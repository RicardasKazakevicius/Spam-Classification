1715.783000 minutes
Ling-Assasin-Enron_500_Tuned:
Emails: 8689
Words: 500
Ham: 5312
Spam: 3377

MLP
[ 92.40506329  91.5420023   92.11737629  91.5420023   91.7146145
  91.9447641   92.46260069  92.92289988  92.46260069  92.69275029
  93.15304948  92.63521289  92.46260069  91.4269275   92.69275029
  92.75028769  92.98043728  92.0598389   92.57767549  92.17491369
  91.8296893   91.7721519   91.4269275   93.26812428  92.80782509
  92.46260069  92.17491369  92.69275029  91.3118527   91.3693901
  91.9447641   92.57767549  91.2543153   92.92289988  92.98043728
  91.6570771   91.4269275   91.7146145   91.4844649   92.46260069
  92.28998849  92.11737629  92.28998849  92.40506329  91.3118527
  91.6570771   92.0023015   91.8296893   93.72842348  92.80782509
  92.28998849  93.72842348  93.95857307  92.34752589  93.67088608
  92.23245109  93.32566168  92.80782509  92.23245109  92.0023015
  92.0023015   92.11737629  91.08170311  92.52013809  92.40506329
  93.49827388  92.52013809  92.23245109  91.4269275   93.09551208
  92.11737629  92.28998849  93.15304948  93.03797468  93.09551208
  92.75028769  92.0598389   93.09551208  91.4844649   92.80782509
  90.85155351  91.7721519   92.46260069  92.11737629  93.44073648
  92.86536249  92.98043728  92.17491369  92.34752589  92.0598389
  91.6570771   92.34752589  92.52013809  92.0598389   93.61334868
  92.57767549  92.34752589  93.15304948  93.09551208  92.34752589]
92.37
0.65
[2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 3 2 2 2 1 2 2 2 2 2]
LinearSVC
[ 91.02416571  89.06789413  90.44879171  89.01035673  89.87341772
  90.27617952  90.04602992  90.67894131  90.10356732  89.75834292
  91.13924051  90.21864212  90.67894131  88.55005754  90.39125432
  90.96662831  90.96662831  90.85155351  89.98849252  90.79401611
  90.73647871  88.95281933  88.66513234  91.2543153   90.21864212
  91.19677791  90.27617952  89.35558113  89.18296893  90.04602992
  89.41311853  90.56386651  89.87341772  91.4269275   90.79401611
  90.44879171  88.89528193  89.93095512  89.41311853  90.56386651
  90.67894131  90.44879171  90.04602992  90.44879171  89.41311853
  90.62140391  89.98849252  90.67894131  90.85155351  90.96662831
  89.98849252  91.02416571  91.4269275   89.93095512  90.96662831
  89.87341772  90.85155351  91.13924051  89.87341772  89.98849252
  89.52819333  90.10356732  89.29804373  89.52819333  90.44879171
  91.8872267   90.16110472  90.10356732  90.10356732  91.08170311
  90.33371692  90.27617952  91.08170311  89.98849252  91.3118527
  91.6570771   90.50632911  91.19677791  88.89528193  90.90909091
  89.12543153  89.87341772  90.50632911  89.47065593  91.5995397
  90.21864212  90.39125432  90.04602992  90.73647871  90.21864212
  89.98849252  89.87341772  89.93095512  89.98849252  91.8872267
  91.02416571  89.87341772  90.85155351  90.62140391  90.67894131]
90.31
0.71
[5 6 5 5 5 4 4 5 5 6 4 4 4 6 5 4 5 4 6 4 4 4 6 4 5 5 5 6 4 5 6 5 5 4 4 4 6
 6 5 5 5 3 5 5 5 5 5 4 5 5 5 5 4 5 6 5 6 5 5 6 5 6 6 5 5 4 4 5 4 4 5 4 5 6
 4 5 3 6 5 5 5 5 5 5 5 5 4 4 5 4 4 6 5 5 5 5 4 5 6 5]
SVC
[ 91.08170311  89.35558113  89.98849252  89.01035673  89.58573072
  90.21864212  89.29804373  90.73647871  89.52819333  89.93095512
  90.67894131  89.75834292  90.27617952  88.83774453  89.93095512
  90.33371692  90.79401611  90.62140391  90.16110472  90.56386651
  90.27617952  88.60759494  89.06789413  91.19677791  89.93095512
  90.67894131  90.04602992  90.27617952  89.12543153  89.87341772
  89.75834292  89.70080552  89.18296893  91.2543153   90.62140391
  90.33371692  88.95281933  90.10356732  88.95281933  90.44879171
  90.67894131  90.21864212  88.95281933  90.16110472  88.66513234
  89.98849252  89.24050633  90.16110472  90.67894131  90.62140391
  89.47065593  90.90909091  91.08170311  89.01035673  91.02416571
  89.87341772  90.96662831  91.2543153   90.04602992  90.56386651
  89.41311853  90.16110472  90.04602992  89.35558113  89.87341772
  91.08170311  90.04602992  89.12543153  89.64326812  90.44879171
  89.98849252  90.16110472  90.67894131  90.27617952  90.90909091
  91.4269275   89.81588032  91.2543153   88.78020713  90.10356732
  88.78020713  89.29804373  90.27617952  89.64326812  90.90909091
  90.10356732  90.16110472  89.52819333  90.62140391  89.98849252
  89.70080552  89.93095512  89.75834292  89.98849252  91.2543153
  90.96662831  89.35558113  90.73647871  90.85155351  90.44879171]
90.08
0.69
[4 5 6 5 6 6 6 4 6 4 6 6 6 4 6 6 6 6 5 6 6 6 5 5 6 6 6 4 5 6 4 6 6 5 6 5 4
 5 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 5 5 5 4 4 4 6 5 4 6 6 6 5 6 6 6 6 5 6 4
 6 6 6 5 6 6 6 6 6 4 6 6 6 6 6 6 6 4 6 5 6 6 6 6 5 6]
DecisionTree
[ 88.83774453  87.57192175  87.74453395  87.62945915  86.53624856
  87.34177215  86.93901036  87.39930955  87.28423475  87.57192175
  87.74453395  88.31990794  86.53624856  87.45684695  87.91714614
  86.99654776  88.08975834  88.14729574  88.08975834  87.28423475
  88.14729574  86.88147296  87.22669735  89.18296893  88.37744534
  88.08975834  87.16915995  88.20483314  87.97468354  87.57192175
  87.11162255  88.14729574  88.14729574  88.14729574  87.97468354
  87.28423475  87.11162255  87.57192175  87.28423475  87.05408516
  87.57192175  88.08975834  88.49252014  86.47871116  87.39930955
  88.26237054  86.82393556  87.22669735  88.49252014  87.68699655
  86.65132336  88.26237054  89.52819333  87.80207135  88.08975834
  87.05408516  87.22669735  88.66513234  86.47871116  87.39930955
  86.82393556  86.07594937  87.16915995  88.55005754  87.05408516
  89.29804373  86.53624856  88.37744534  87.80207135  88.60759494
  87.05408516  87.62945915  87.91714614  88.72266974  87.80207135
  87.62945915  88.55005754  89.06789413  86.82393556  88.49252014
  86.24856157  87.85960875  86.88147296  88.43498274  87.57192175
  87.68699655  89.01035673  86.82393556  88.08975834  87.51438435
  87.57192175  88.08975834  87.11162255  88.37744534  87.74453395
  88.14729574  87.68699655  87.45684695  88.14729574  87.16915995]
87.69
0.70
[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]
k-NN
[ 84.46490219  83.716916    83.6018412   83.0264672   84.34982739
  83.429229    83.88952819  84.98273878  84.81012658  84.46490219
  84.46490219  84.63751438  82.56616801  83.0840046   84.34982739
  84.46490219  84.23475259  81.99079402  84.57997699  84.57997699
  83.77445339  81.47295742  83.716916    84.29228999  86.01841197
  82.73878021  84.11967779  84.57997699  82.16340621  84.06214039
  82.85385501  85.61565017  84.34982739  86.36363636  83.94706559
  84.23475259  83.77445339  83.94706559  83.1990794   83.77445339
  84.63751438  82.9689298   83.88952819  83.716916    83.77445339
  84.17721519  85.09781358  84.17721519  83.2566168   86.24856157
  83.4867664   84.75258918  85.04027618  83.94706559  85.90333717
  83.429229    83.141542    84.63751438  84.63751438  85.09781358
  83.4867664   83.429229    84.69505178  84.34982739  85.09781358
  85.15535098  83.1990794   84.23475259  84.92520138  86.70886076
  83.6593786   84.34982739  84.29228999  85.90333717  86.47871116
  84.11967779  81.81818182  84.06214039  85.50057537  83.429229
  83.77445339  84.00460299  84.40736479  83.77445339  83.77445339
  82.73878021  84.46490219  85.50057537  84.69505178  84.06214039
  83.88952819  84.98273878  85.44303797  85.55811277  84.98273878
  85.27042578  84.52243959  85.78826237  84.86766398  84.29228999]
84.24
0.99
[ 8  9  8  8  8  8  8  8  8  8  9  8  9  8  8  8  8  9  8  8  9  9  8  8  8
  8  9  8  8  8  9  8  8  8  8  8  8  8  9  9  8  8  8  8  8  9  8  8  8  8
  8  8  8  8  8  9  8  8  8  8  8  8  8  8  8  8  9  8  8  8  8  8  8  8  8
  8 10  9  8  8  8  8  8  8  8  9  8  8  8  8  9  8  8  8  8  8  8  8  8  8]
LogisticRegression
[ 90.79401611  89.47065593  90.56386651  89.58573072  90.27617952
  90.27617952  89.93095512  90.56386651  90.27617952  89.93095512
  90.96662831  90.16110472  90.56386651  88.83774453  90.44879171
  90.90909091  91.13924051  90.85155351  90.56386651  91.19677791
  90.67894131  88.83774453  89.18296893  91.19677791  90.56386651
  91.5420023   90.33371692  90.10356732  89.01035673  90.21864212
  89.70080552  90.79401611  89.93095512  91.2543153   90.67894131
  90.33371692  88.95281933  90.21864212  89.64326812  90.73647871
  91.08170311  90.33371692  90.33371692  90.90909091  89.52819333
  90.67894131  90.21864212  90.50632911  90.96662831  91.3118527
  90.16110472  91.3693901   91.3693901   90.10356732  91.3693901
  89.98849252  91.7721519   91.08170311  89.75834292  90.33371692
  89.75834292  90.39125432  89.75834292  89.70080552  91.02416571
  91.7721519   90.21864212  90.16110472  89.98849252  90.90909091
  90.39125432  90.04602992  91.7721519   90.27617952  90.96662831
  91.7721519   90.27617952  91.7146145   89.70080552  91.4269275
  89.52819333  89.98849252  90.79401611  89.47065593  91.7146145
  90.62140391  90.27617952  90.04602992  90.96662831  90.04602992
  89.93095512  89.93095512  90.44879171  90.44879171  92.0598389
  91.2543153   89.87341772  91.2543153   91.3693901   90.79401611]
90.47
0.70
[6 4 4 4 4 4 5 6 4 4 5 5 5 4 4 5 4 4 4 3 5 5 4 5 4 4 4 5 6 4 5 4 4 5 5 5 4
 4 4 4 4 5 4 4 4 4 4 5 4 4 4 3 5 4 4 4 4 6 6 5 4 3 5 4 4 5 3 4 5 5 4 6 3 4
 5 4 5 4 4 4 4 4 4 5 4 4 5 4 4 5 5 4 4 4 4 3 4 4 4 4]
MultinomialNB
[ 81.12773303  82.16340621  80.60989643  81.01265823  80.89758343
  79.51668585  80.60989643  81.81818182  80.09205984  82.10586881
  82.45109321  79.68929804  80.66743383  80.55235903  79.80437284
  80.37974684  82.27848101  81.35788262  79.80437284  81.41542002
  82.39355581  81.41542002  79.11392405  81.18527043  81.81818182
  78.99884925  83.141542    82.10586881  78.65362486  80.84004603
  81.35788262  81.81818182  80.49482163  83.0264672   82.16340621
  81.18527043  78.65362486  79.91944764  81.24280783  82.56616801
  81.01265823  80.03452244  81.18527043  81.53049482  79.91944764
  81.81818182  81.47295742  80.03452244  79.57422325  81.87571922
  80.49482163  81.53049482  80.37974684  82.33601841  81.64556962
  81.99079402  79.97698504  81.12773303  81.76064442  80.49482163
  81.12773303  81.64556962  81.81818182  81.47295742  81.18527043
  80.60989643  80.89758343  83.0264672   81.76064442  82.27848101
  79.97698504  80.49482163  80.78250863  81.81818182  80.78250863
  82.16340621  82.10586881  81.76064442  79.34407365  80.60989643
  82.16340621  80.37974684  80.37974684  80.14959724  82.27848101
  79.97698504  81.58803222  81.87571922  82.45109321  79.40161105
  83.1990794   81.53049482  81.47295742  81.70310702  81.99079402
  80.32220944  80.78250863  80.72497123  80.55235903  82.33601841]
81.12
1.01
[10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10
 10  9 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]
BernoulliNB
[ 83.94706559  83.88952819  82.33601841  82.33601841  83.0264672
  81.12773303  83.2566168   84.17721519  81.30034522  84.40736479
  84.75258918  81.76064442  83.0264672   81.53049482  82.04833142
  83.3141542   84.06214039  83.0840046   82.04833142  82.79631761
  84.52243959  83.3141542   80.66743383  82.85385501  83.716916
  82.62370541  84.46490219  84.06214039  81.93325662  83.141542
  84.69505178  82.73878021  82.04833142  84.06214039  83.88952819
  82.85385501  80.66743383  82.85385501  83.716916    85.61565017
  83.716916    82.73878021  82.85385501  82.27848101  81.76064442
  84.63751438  83.3716916   83.0264672   82.04833142  83.716916
  82.91139241  84.69505178  81.58803222  83.0840046   82.85385501
  83.6593786   82.45109321  84.00460299  82.91139241  83.141542    83.1990794
  82.39355581  83.1990794   84.00460299  83.2566168   83.4867664
  83.2566168   84.06214039  82.85385501  84.86766398  81.35788262
  83.5443038   83.77445339  83.1990794   83.5443038   83.5443038
  83.6593786   84.86766398  80.60989643  82.10586881  83.716916    83.6018412
  82.91139241  83.0264672   83.0264672   83.141542    84.40736479
  84.75258918  84.17721519  81.70310702  84.69505178  84.40736479
  83.5443038   83.83199079  84.40736479  83.94706559  83.77445339
  82.68124281  83.429229    83.716916  ]
83.22
1.01
[9 8 9 9 9 9 9 9 9 9 8 9 8 9 9 9 9 8 9 9 8 8 9 9 9 9 8 9 9 9 8 9 9 9 9 9 9
 9 8 8 9 9 9 9 9 8 9 9 9 9 9 9 9 9 9 8 9 9 9 9 9 9 9 9 9 9 8 9 9 9 9 9 9 9
 9 9 8 8 9 9 9 9 9 9 9 8 9 9 9 9 8 9 9 9 9 9 9 9 9 9]
AdaBoost
[ 91.5420023   91.5995397   90.73647871  90.85155351  90.79401611
  91.8296893   90.90909091  91.6570771   91.7721519   92.28998849
  92.17491369  91.3693901   91.3693901   90.67894131  91.5995397
  91.6570771   92.17491369  91.4269275   91.5995397   90.62140391
  91.08170311  90.73647871  90.33371692  91.6570771   91.4269275
  91.6570771   90.50632911  91.02416571  90.79401611  91.08170311
  92.0023015   91.02416571  90.85155351  92.0598389   91.9447641
  92.0598389   90.10356732  90.85155351  90.96662831  90.96662831
  91.19677791  90.44879171  91.4844649   91.13924051  90.44879171
  91.3693901   91.3118527   91.02416571  92.28998849  91.8872267
  91.3693901   91.3693901   92.46260069  91.3118527   92.23245109
  91.4269275   91.8296893   91.3693901   91.7146145   91.02416571
  91.2543153   90.33371692  90.62140391  91.5420023   91.2543153
  92.80782509  89.87341772  91.7721519   91.02416571  91.3118527
  91.3693901   91.5420023   91.4269275   91.5420023   91.7721519
  91.8296893   90.50632911  92.0023015   90.33371692  92.34752589
  90.04602992  91.3118527   91.2543153   91.02416571  92.23245109
  91.13924051  90.67894131  91.6570771   91.8872267   90.79401611
  91.7146145   91.19677791  91.3693901   91.08170311  92.63521289
  91.2543153   91.4844649   91.7721519   91.4844649   91.8872267 ]
91.35
0.58
[3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 2 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 6 3 3 3 3 3 4 3
 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3]
RandomForest
[ 93.44073648  93.67088608  93.49827388  92.80782509  92.92289988
  93.49827388  93.32566168  93.78596087  93.61334868  93.95857307
  93.55581128  93.67088608  92.63521289  92.63521289  94.13118527
  93.78596087  93.55581128  93.21058688  93.90103567  93.32566168
  93.90103567  93.15304948  93.21058688  94.07364787  93.84349827
  93.67088608  93.26812428  93.55581128  93.72842348  92.92289988
  93.72842348  93.44073648  93.15304948  93.95857307  93.90103567
  92.98043728  92.17491369  93.32566168  93.26812428  92.86536249
  93.32566168  93.38319908  93.49827388  92.98043728  92.40506329
  92.52013809  92.86536249  92.69275029  94.36133487  93.95857307
  92.98043728  94.30379747  94.30379747  93.38319908  93.61334868
  93.03797468  93.95857307  93.49827388  93.15304948  92.98043728
  93.55581128  92.34752589  92.11737629  93.72842348  93.38319908
  94.64902186  93.21058688  93.32566168  92.98043728  93.21058688
  93.15304948  93.09551208  93.90103567  94.01611047  93.32566168
  93.78596087  93.61334868  94.01611047  92.63521289  94.01611047
  92.75028769  93.61334868  93.15304948  93.84349827  93.21058688
  93.09551208  92.92289988  93.38319908  93.15304948  93.09551208
  93.72842348  94.13118527  93.67088608  93.21058688  93.44073648
  93.38319908  93.67088608  94.07364787  94.30379747  93.38319908]
93.42
0.49
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1]

MLP
Number of parameters combination: 16
LinearSVC
Number of parameters combination: 8
SVC
Number of parameters combination: 24
DecisionTree
Number of parameters combination: 72
k-NN
Number of parameters combination: 96
LogisticRegression
Number of parameters combination: 16
MultinomialNB
Number of parameters combination: 12
BernoulliNB
Number of parameters combination: 72
AdaBoost
Number of parameters combination: 50
RandomForest
Number of parameters combination: 72

<bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=100000, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)>
<bound method LinearSVC.get_params of LinearSVC(C=0.5, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,
     verbose=0)>
<bound method SVC.get_params of SVC(C=1.5, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovo', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)>
<bound method DecisionTreeClassifier.get_params of DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=6,
            min_weight_fraction_leaf=0.0, presort=True, random_state=None,
            splitter='best')>
<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=3, p=2,
           weights='distance')>
<bound method LogisticRegression.get_params of LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)>
<bound method MultinomialNB.get_params of MultinomialNB(alpha=1e-10, class_prior=None, fit_prior=True)>
<bound method BernoulliNB.get_params of BernoulliNB(alpha=1e-10, binarize=0.0, class_prior=None, fit_prior=True)>
<bound method AdaBoostClassifier.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=500, random_state=None)>
<bound method RandomForestClassifier.get_params of RandomForestClassifier(bootstrap=False, class_weight=None,
            criterion='entropy', max_depth=None, max_features='log2',
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=1,
            min_samples_split=6, min_weight_fraction_leaf=0.0,
            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,
            verbose=0, warm_start=False)>
