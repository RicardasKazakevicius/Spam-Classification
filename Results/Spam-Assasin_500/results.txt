49.411900 minutes
Spam-Assasin_500:
Emails: 6046
Words: 500
Ham: 4150
Spam: 1896

MLP
[ 91.81818182  91.57024793  91.32231405  91.73553719  92.23140496
  90.33057851  91.15702479  91.07438017  90.74380165  91.81818182
  90.90909091  91.40495868  91.65289256  91.15702479  91.57024793
  90.90909091  90.41322314  91.32231405  92.0661157   91.15702479
  89.83471074  90.16528926  90.66115702  89.83471074  91.23966942
  91.65289256  91.23966942  92.56198347  90.90909091  90.5785124
  92.80991736  91.48760331  93.2231405   91.81818182  92.80991736
  90.5785124   91.15702479  91.40495868  91.48760331  91.90082645
  92.6446281   90.74380165  90.24793388  91.81818182  92.14876033
  90.74380165  92.0661157   90.82644628  91.81818182  90.41322314
  90.90909091  89.25619835  91.57024793  90.90909091  90.90909091
  89.75206612  91.40495868  91.32231405  90.16528926  91.07438017
  91.98347107  91.48760331  90.99173554  91.73553719  92.56198347
  91.15702479  91.65289256  91.32231405  91.07438017  90.90909091
  90.90909091  91.15702479  90.90909091  90.82644628  92.80991736
  91.48760331  91.65289256  90.41322314  91.57024793  90.5785124
  91.23966942  91.57024793  91.81818182  90.33057851  92.14876033
  91.48760331  92.6446281   90.66115702  90.          90.41322314
  91.57024793  89.58677686  91.07438017  90.33057851  90.49586777
  92.56198347  90.82644628  92.47933884  89.75206612  91.98347107]
91.25
0.79
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]
LinearSVC
[ 89.83471074  87.68595041  88.34710744  89.09090909  89.83471074
  87.60330579  89.33884298  87.43801653  88.92561983  88.59504132
  87.9338843   87.76859504  89.83471074  88.67768595  87.85123967
  87.60330579  87.68595041  88.01652893  87.76859504  88.42975207
  87.76859504  88.01652893  87.76859504  87.19008264  87.43801653
  88.34710744  88.34710744  89.50413223  89.17355372  86.28099174
  89.50413223  87.43801653  89.09090909  89.83471074  88.67768595
  88.26446281  88.42975207  89.58677686  88.67768595  88.42975207
  89.25619835  89.09090909  88.34710744  89.50413223  89.4214876
  88.76033058  89.09090909  87.9338843   89.09090909  87.9338843
  85.8677686   86.19834711  88.84297521  88.18181818  88.18181818
  87.10743802  88.26446281  87.19008264  89.00826446  88.92561983
  88.67768595  87.85123967  88.92561983  90.5785124   89.33884298
  87.85123967  89.09090909  87.85123967  87.85123967  88.18181818
  88.34710744  88.67768595  87.85123967  89.83471074  90.16528926
  88.26446281  89.91735537  88.51239669  88.09917355  87.60330579
  89.00826446  87.76859504  88.26446281  87.9338843   90.          88.18181818
  88.84297521  89.00826446  88.51239669  87.27272727  89.09090909
  88.42975207  88.09917355  88.42975207  87.27272727  89.00826446
  88.67768595  89.50413223  86.11570248  88.92561983]
88.44
0.89
[3 4 5 4 3 3 4 4 4 4 4 4 2 4 3 5 3 3 5 3 4 4 4 4 4 4 3 5 4 5 4 5 3 3 4 3 5
 3 4 4 4 4 4 3 3 3 4 3 3 3 5 5 4 4 5 3 6 5 4 4 3 5 4 4 3 5 4 5 4 4 4 4 5 3
 3 3 2 3 5 4 4 4 4 4 4 3 4 4 3 4 3 4 4 4 4 3 4 4 5 3]
SVC
[ 85.12396694  84.04958678  84.7107438   86.28099174  85.78512397
  83.55371901  85.37190083  84.04958678  85.78512397  85.20661157
  84.79338843  85.53719008  86.28099174  84.04958678  85.37190083
  82.80991736  84.87603306  84.7107438   84.79338843  84.1322314
  86.11570248  84.7107438   83.63636364  84.46280992  84.46280992
  83.88429752  85.12396694  86.61157025  85.61983471  83.05785124
  84.87603306  85.20661157  86.94214876  85.12396694  84.21487603
  83.55371901  84.38016529  85.20661157  85.45454545  84.21487603
  84.79338843  85.45454545  85.61983471  85.78512397  86.61157025
  84.38016529  84.54545455  83.63636364  83.38842975  83.80165289
  83.47107438  84.29752066  84.46280992  84.95867769  85.78512397
  83.30578512  85.2892562   83.71900826  85.95041322  84.04958678
  84.7107438   85.78512397  84.1322314   87.19008264  85.53719008
  83.96694215  85.61983471  84.7107438   84.79338843  84.46280992
  84.95867769  84.1322314   86.44628099  86.44628099  86.19834711
  85.2892562   85.45454545  84.7107438   84.95867769  84.21487603
  84.79338843  83.30578512  85.53719008  84.38016529  86.52892562
  82.31404959  83.38842975  86.28099174  83.47107438  84.1322314
  84.54545455  86.44628099  83.96694215  84.7107438   84.29752066
  86.19834711  84.95867769  86.03305785  83.14049587  84.04958678]
84.84
1.00
[ 9  8  9  7  7  9  9  9  8  8  9  8  8  8  8 10  9  9  9  9  7  6 10  8  9
  9  7  7  8  8  8  7  8  8  9  9  8  8  8  9  9  8  8  9  9  9  8 10 10  9
  9  8  9  8  8 10  8  9  8  9  8  7  8  8  8  8  8  8  8  9  8  9  7  7  8
  8  8  8  8  8  8  8  7  8  7 10  9  8  8  9  9  7  9  8  9  8  9  7  9  9]
DecisionTree
[ 85.70247934  85.04132231  85.20661157  84.29752066  85.2892562
  85.12396694  82.14876033  86.52892562  83.55371901  84.21487603
  86.52892562  85.04132231  84.87603306  83.55371901  85.95041322
  84.38016529  86.03305785  85.8677686   85.37190083  84.54545455
  84.87603306  84.46280992  84.62809917  82.39669421  85.04132231
  85.04132231  83.96694215  84.1322314   83.63636364  82.89256198
  83.71900826  84.95867769  84.62809917  84.7107438   84.46280992
  84.62809917  84.21487603  85.04132231  84.04958678  85.61983471
  86.7768595   85.45454545  85.45454545  87.68595041  87.60330579
  85.53719008  84.29752066  86.19834711  84.95867769  84.46280992
  85.2892562   83.14049587  85.70247934  82.14876033  85.45454545
  83.38842975  85.12396694  85.37190083  83.38842975  85.20661157
  84.29752066  84.54545455  82.23140496  84.04958678  84.7107438
  82.89256198  84.62809917  84.21487603  84.1322314   85.53719008
  82.72727273  85.04132231  84.95867769  84.7107438   85.78512397
  82.0661157   85.2892562   83.88429752  83.71900826  84.46280992
  84.38016529  83.2231405   84.62809917  82.97520661  85.53719008
  86.94214876  85.61983471  83.88429752  82.47933884  85.12396694
  85.20661157  81.98347107  84.04958678  85.20661157  84.54545455
  86.19834711  85.2892562   85.53719008  84.1322314   84.29752066]
84.64
1.15
[ 8  7  8  9  8  6 10  6  9  9  7  9  9  9  7  8  6  7  8  8  9  9  7 10  7
  7  9 10  9  9  9  8  9  9  8  7 10  9 10  7  7  8  9  6  6  7  9  6  8  8
  6  9  8  9  9  9  9  7 10  8  9  9  9 10  9 10  9  9  9  8  9  8  9  9  9
  9  9  9  9  7  9  9  9  9  9  6  8  9 10  8  8 10  8  7  8  8  8  9  7  8]
k-NN
[ 82.0661157   82.89256198  83.38842975  79.17355372  83.47107438
  80.5785124   85.53719008  83.30578512  81.23966942  82.89256198
  84.54545455  84.04958678  84.79338843  81.81818182  82.72727273
  83.47107438  83.80165289  84.62809917  83.14049587  83.2231405
  82.6446281   82.72727273  84.38016529  83.71900826  82.6446281
  79.17355372  80.08264463  85.8677686   83.63636364  82.6446281
  80.74380165  83.30578512  83.14049587  82.89256198  80.74380165
  79.50413223  84.38016529  84.04958678  85.20661157  80.16528926
  81.98347107  84.21487603  83.96694215  84.29752066  85.04132231
  82.6446281   81.81818182  83.96694215  83.88429752  82.80991736
  84.04958678  82.80991736  83.55371901  81.32231405  84.7107438
  83.96694215  84.95867769  82.97520661  85.2892562   83.38842975
  81.65289256  83.63636364  80.90909091  85.61983471  81.73553719
  83.30578512  81.90082645  83.80165289  81.07438017  81.81818182
  82.23140496  80.08264463  82.0661157   81.07438017  82.14876033
  80.16528926  82.72727273  82.0661157   81.57024793  81.90082645
  83.47107438  82.56198347  84.1322314   82.6446281   82.72727273
  84.54545455  82.72727273  83.38842975  82.89256198  83.88429752
  80.49586777  82.80991736  82.97520661  83.63636364  81.23966942
  84.21487603  81.90082645  81.73553719  82.47933884  81.98347107]
82.82
1.46
[10 10 10 10 10 10  8 10 10 10 10 10 10 10 10  9 10 10 10 10 10 10  8  9 10
 10 10  9  9 10 10 10 10 10 10 10  8 10  9 10 10 10 10 10 10 10 10  9  9 10
  8 10 10 10 10  6 10 10  9 10 10 10 10  9 10  9 10 10 10 10 10 10 10 10 10
 10 10 10 10 10 10 10 10 10 10  7 10 10  9 10 10  9 10 10 10 10 10 10 10 10]
LogisticRegression
[ 90.          87.68595041  88.84297521  89.66942149  89.91735537
  87.60330579  90.          88.09917355  89.50413223  88.84297521
  88.51239669  88.59504132  89.17355372  89.66942149  87.60330579
  87.85123967  87.52066116  88.01652893  87.9338843   88.42975207
  88.34710744  88.18181818  88.09917355  87.68595041  88.42975207
  88.59504132  89.25619835  90.66115702  89.25619835  87.27272727
  90.41322314  87.76859504  89.00826446  90.41322314  89.25619835
  88.01652893  89.25619835  90.          89.00826446  88.76033058  90.
  89.33884298  88.92561983  89.4214876   89.00826446  88.92561983
  89.33884298  87.85123967  88.92561983  87.85123967  86.52892562
  87.27272727  89.17355372  88.09917355  88.34710744  86.94214876
  89.25619835  87.27272727  89.66942149  89.00826446  88.34710744
  88.18181818  89.4214876   90.90909091  89.17355372  88.67768595
  90.08264463  88.51239669  88.34710744  88.76033058  88.42975207
  89.33884298  88.42975207  90.16528926  90.24793388  89.00826446
  89.50413223  89.50413223  88.18181818  88.18181818  89.17355372
  88.42975207  88.59504132  87.85123967  90.08264463  87.9338843   90.
  89.91735537  88.84297521  87.9338843   89.58677686  88.92561983
  88.67768595  88.84297521  87.76859504  89.00826446  89.17355372
  89.83471074  87.19008264  88.42975207]
88.80
0.89
[2 4 3 3 2 3 2 3 3 3 3 3 4 2 5 3 4 3 4 3 2 3 3 3 3 3 2 2 3 4 2 3 5 2 3 4 2
 2 3 3 3 3 3 4 4 2 3 4 4 4 3 4 3 5 4 4 3 3 2 2 4 3 2 2 4 3 2 3 3 2 3 2 3 2
 2 2 3 2 4 3 3 3 3 5 3 4 2 2 2 3 2 2 3 3 3 3 2 3 3 4]
MultinomialNB
[ 88.51239669  87.9338843   88.84297521  88.67768595  88.42975207
  86.28099174  88.92561983  87.27272727  87.76859504  86.52892562
  87.52066116  87.60330579  87.9338843   87.52066116  87.76859504
  87.68595041  87.27272727  87.27272727  88.59504132  88.18181818
  87.60330579  87.19008264  85.12396694  85.78512397  86.69421488
  88.09917355  88.18181818  89.58677686  88.34710744  87.68595041
  88.18181818  87.76859504  89.09090909  88.92561983  86.7768595
  87.27272727  89.25619835  88.67768595  86.28099174  87.43801653
  87.85123967  88.18181818  88.09917355  88.51239669  88.59504132
  87.43801653  87.9338843   86.94214876  87.27272727  88.42975207
  86.28099174  87.43801653  89.66942149  88.42975207  88.01652893
  84.87603306  88.59504132  87.27272727  89.09090909  87.3553719
  88.18181818  88.18181818  87.3553719   90.74380165  89.17355372
  88.09917355  88.42975207  88.01652893  87.3553719   88.42975207
  86.7768595   88.26446281  88.26446281  88.42975207  88.59504132
  87.52066116  87.9338843   88.09917355  88.59504132  86.44628099
  88.67768595  86.61157025  88.01652893  87.43801653  88.92561983
  87.76859504  87.85123967  88.09917355  86.94214876  87.19008264
  87.68595041  87.85123967  88.01652893  88.01652893  86.94214876
  87.60330579  87.76859504  88.42975207  86.69421488  88.42975207]
87.85
0.90
[6 3 3 5 5 5 5 5 5 6 5 5 5 5 4 4 5 5 3 5 5 5 6 6 5 5 5 4 5 3 5 3 3 5 5 5 2
 5 5 5 5 5 5 5 5 5 5 5 5 2 4 2 2 2 6 5 4 3 3 5 5 3 5 3 4 4 5 4 5 3 6 5 4 5
 5 5 6 4 3 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 4]
BernoulliNB
[ 89.25619835  85.53719008  86.36363636  88.26446281  86.7768595
  84.87603306  88.26446281  86.19834711  87.10743802  86.03305785
  86.61157025  86.52892562  87.19008264  85.37190083  87.27272727
  84.87603306  85.53719008  87.02479339  87.60330579  84.62809917
  87.19008264  84.7107438   86.28099174  85.95041322  84.79338843
  86.7768595   86.19834711  88.76033058  87.02479339  85.12396694
  87.52066116  86.94214876  89.00826446  86.7768595   86.7768595
  86.11570248  86.28099174  86.28099174  86.19834711  86.52892562
  87.60330579  87.02479339  86.94214876  87.68595041  87.60330579
  86.61157025  86.52892562  85.53719008  86.03305785  85.61983471
  83.30578512  85.95041322  87.68595041  85.8677686   88.59504132
  83.80165289  88.51239669  86.44628099  87.68595041  86.52892562
  85.12396694  86.61157025  87.02479339  90.33057851  86.11570248
  86.52892562  87.43801653  86.61157025  86.11570248  87.60330579
  86.69421488  86.36363636  87.52066116  88.26446281  86.52892562
  87.3553719   88.09917355  86.61157025  86.69421488  85.61983471
  86.7768595   86.44628099  86.36363636  88.84297521  87.76859504
  82.56198347  86.61157025  87.10743802  85.37190083  85.2892562
  85.78512397  86.94214876  84.87603306  87.52066116  86.44628099
  87.10743802  86.94214876  87.3553719   84.87603306  85.95041322]
86.60
1.22
[ 4  6  7  6  6  7  6  7  6  7  6  7  6  6  6  6  7  6  6  7  6  6  5  5  8
  6  6  6  6  6  6  6  5  6  5  6  6  7  7  6  6  6  6  6  6  6  6  8  6  6
 10  6  6  7  3  7  5  6  6  6  6  6  6  5  7  6  6  6  6  6  7  6  6  6  7
  6  4  6  6  6  6  6  6  3  6  9  6  6  6  7  7  6  7  6  6  7  6  6  6  6]
AdaBoost
[ 86.94214876  83.47107438  86.61157025  85.53719008  85.2892562
  84.54545455  85.95041322  86.03305785  86.36363636  86.61157025
  85.20661157  86.69421488  86.7768595   85.2892562   84.95867769
  84.87603306  84.95867769  85.70247934  85.53719008  85.70247934
  85.45454545  84.54545455  84.04958678  84.54545455  86.28099174
  84.7107438   84.38016529  86.61157025  85.70247934  84.79338843
  85.53719008  84.79338843  88.26446281  85.37190083  85.95041322
  84.54545455  86.11570248  86.36363636  86.28099174  85.12396694
  85.78512397  86.61157025  85.8677686   86.7768595   87.10743802
  84.95867769  85.2892562   86.03305785  85.8677686   85.53719008
  84.46280992  85.2892562   86.44628099  86.19834711  86.28099174
  83.47107438  85.78512397  85.20661157  86.03305785  86.28099174
  84.87603306  85.78512397  85.95041322  88.09917355  86.7768595
  85.95041322  85.95041322  85.78512397  85.12396694  86.44628099
  87.19008264  86.03305785  86.19834711  85.61983471  86.61157025
  85.37190083  86.69421488  86.11570248  86.61157025  83.71900826
  86.11570248  83.71900826  85.45454545  86.52892562  86.03305785
  84.38016529  85.70247934  86.69421488  84.21487603  85.37190083
  85.95041322  85.53719008  85.78512397  83.88429752  86.03305785
  87.27272727  85.95041322  85.70247934  83.38842975  85.95041322]
85.68
0.94
[7 9 6 8 8 8 7 8 7 5 8 6 7 7 9 6 8 8 7 6 8 8 9 7 6 8 8 7 7 7 7 9 7 7 7 8 7
 6 5 8 8 7 7 8 8 8 7 7 7 7 7 7 7 6 7 8 7 8 7 7 7 7 7 7 6 7 7 7 7 7 5 7 8 8
 6 7 7 7 7 9 7 7 8 7 8 8 7 7 7 6 6 8 6 9 7 6 7 8 8 6]
RandomForest
[ 88.76033058  89.75206612  90.33057851  90.41322314  88.67768595
  88.09917355  89.4214876   89.50413223  90.          90.16528926
  89.17355372  89.09090909  89.4214876   88.76033058  89.66942149
  90.16528926  89.66942149  89.50413223  90.41322314  88.59504132
  88.01652893  88.84297521  89.75206612  88.26446281  89.66942149
  89.66942149  88.34710744  90.5785124   89.83471074  88.59504132
  90.24793388  89.25619835  89.66942149  89.25619835  89.66942149
  89.00826446  88.92561983  89.58677686  90.08264463  90.49586777
  90.82644628  90.          89.50413223  91.23966942  90.08264463
  88.09917355  89.4214876   90.74380165  90.24793388  87.3553719
  91.07438017  87.43801653  88.09917355  88.26446281  89.83471074
  87.43801653  89.4214876   89.58677686  88.51239669  89.00826446
  90.08264463  90.24793388  89.00826446  89.17355372  91.15702479
  89.58677686  89.66942149  90.24793388  90.          87.9338843
  89.4214876   89.17355372  90.          88.84297521  90.08264463
  87.76859504  88.09917355  88.09917355  90.          89.17355372
  89.33884298  88.67768595  90.24793388  89.25619835  91.15702479
  90.5785124   89.00826446  89.17355372  88.34710744  88.84297521
  88.59504132  88.76033058  89.33884298  90.66115702  89.50413223
  90.5785124   88.92561983  90.24793388  88.92561983  89.50413223]
89.41
0.87
[5 2 2 2 4 2 3 2 2 2 2 2 3 3 2 2 2 2 2 2 3 2 2 2 2 2 3 3 2 2 3 2 2 4 2 2 4
 3 2 2 2 2 2 2 2 4 2 2 2 5 1 2 5 3 2 2 2 2 5 2 2 2 3 6 2 2 3 2 2 5 2 3 2 4
 4 4 4 4 2 2 2 2 2 2 2 2 3 3 4 2 4 3 2 1 2 2 3 2 2 2]

<bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)>
<bound method LinearSVC.get_params of LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)>
<bound method SVC.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)>
<bound method DecisionTreeClassifier.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')>
<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')>
<bound method LogisticRegression.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)>
<bound method MultinomialNB.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>
<bound method BernoulliNB.get_params of BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)>
<bound method AdaBoostClassifier.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)>
<bound method RandomForestClassifier.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)>
