145.065783 minutes
Ling-Assasin-Enron_500:
Emails: 8689
Words: 500
Ham: 5312
Spam: 3377

MLP
[ 92.23245109  93.15304948  92.34752589  93.61334868  92.57767549
  92.40506329  93.49827388  92.46260069  92.0598389   92.69275029
  91.8296893   91.5995397   93.15304948  91.6570771   92.0598389
  92.52013809  92.46260069  92.11737629  91.4269275   92.75028769
  93.67088608  92.52013809  92.98043728  92.57767549  93.44073648
  92.75028769  92.52013809  92.92289988  92.57767549  92.0598389
  92.23245109  92.86536249  91.5995397   92.23245109  93.03797468
  94.01611047  92.63521289  92.75028769  92.98043728  92.34752589
  92.0023015   91.5995397   91.7146145   91.08170311  92.40506329
  93.44073648  93.21058688  92.80782509  92.40506329  93.49827388
  91.7721519   92.92289988  91.8872267   92.63521289  92.69275029
  92.46260069  92.23245109  92.34752589  92.75028769  92.11737629
  92.69275029  92.80782509  91.4269275   91.5420023   91.7721519
  93.32566168  91.7721519   91.5995397   92.28998849  93.32566168
  92.46260069  92.28998849  92.17491369  92.86536249  92.86536249
  93.21058688  92.0023015   92.28998849  93.03797468  92.80782509
  91.5995397   92.86536249  92.86536249  92.28998849  92.40506329
  92.86536249  92.34752589  92.52013809  91.8872267   92.23245109
  90.67894131  93.09551208  93.55581128  93.44073648  93.55581128
  93.84349827  91.7721519   92.28998849  93.72842348  92.46260069]
92.52
0.64
[1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
LinearSVC
[ 90.04602992  91.3118527   88.66513234  90.67894131  90.27617952
  90.21864212  89.47065593  89.98849252  89.75834292  90.16110472
  89.93095512  90.33371692  89.47065593  89.29804373  89.47065593
  90.50632911  89.41311853  88.72266974  89.93095512  89.24050633
  90.39125432  90.39125432  90.56386651  90.62140391  90.90909091
  90.56386651  90.44879171  90.39125432  90.04602992  89.70080552
  89.98849252  90.79401611  89.12543153  89.29804373  89.93095512
  90.10356732  90.85155351  89.58573072  90.56386651  89.01035673
  89.29804373  90.33371692  89.35558113  89.58573072  90.04602992
  90.21864212  90.62140391  90.21864212  89.06789413  91.08170311
  89.58573072  90.27617952  89.52819333  89.29804373  90.50632911
  89.47065593  90.44879171  89.52819333  90.62140391  89.06789413
  89.70080552  90.50632911  89.18296893  89.41311853  89.93095512
  89.58573072  89.70080552  89.35558113  89.01035673  90.33371692
  91.08170311  89.87341772  90.62140391  89.93095512  89.58573072
  90.44879171  89.29804373  89.41311853  89.98849252  90.33371692
  89.81588032  89.81588032  89.75834292  89.75834292  90.67894131
  90.10356732  90.56386651  89.93095512  90.33371692  90.56386651
  89.87341772  90.21864212  89.47065593  90.79401611  90.62140391
  91.8872267   89.47065593  90.85155351  90.27617952  89.06789413]
89.99
0.60
[4 2 5 4 4 4 4 4 3 4 4 3 4 4 4 4 4 4 3 3 3 4 3 4 3 4 4 4 3 3 3 4 3 3 4 3 4
 3 3 4 3 3 4 4 4 4 4 3 3 4 3 4 3 4 4 3 2 3 3 4 3 3 4 3 4 4 4 3 4 4 3 4 3 4
 4 3 4 4 4 3 4 4 4 4 3 4 3 3 4 4 3 3 3 2 3 2 4 3 5 4]
SVC
[ 86.53624856  88.08975834  89.12543153  87.74453395  87.05408516
  86.70886076  86.42117376  86.82393556  86.30609896  87.05408516
  88.89528193  87.11162255  87.28423475  85.84579977  88.03222094
  87.68699655  87.97468354  86.65132336  86.36363636  85.84579977
  87.16915995  87.16915995  87.28423475  87.51438435  85.55811277
  88.78020713  87.22669735  87.80207135  87.16915995  86.47871116
  86.99654776  88.31990794  86.30609896  85.96087457  87.80207135
  86.88147296  87.45684695  87.97468354  87.39930955  87.11162255
  86.07594937  87.45684695  87.51438435  87.11162255  86.88147296
  88.14729574  86.36363636  87.22669735  87.16915995  89.01035673
  86.59378596  87.11162255  85.84579977  87.34177215  86.76639816
  86.47871116  86.82393556  86.19102417  88.72266974  88.14729574
  86.93901036  87.11162255  88.03222094  86.76639816  86.88147296
  87.68699655  86.24856157  87.05408516  86.59378596  87.34177215
  86.59378596  87.68699655  87.45684695  86.70886076  86.53624856
  87.57192175  86.99654776  87.45684695  87.91714614  86.76639816
  87.16915995  88.89528193  88.14729574  88.14729574  88.14729574
  87.91714614  87.91714614  87.97468354  87.05408516  86.93901036
  87.68699655  87.74453395  87.57192175  87.97468354  86.65132336
  86.19102417  87.16915995  86.36363636  88.37744534  86.76639816]
87.24
0.76
[6 5 4 5 6 5 6 6 6 5 5 5 6 6 5 5 5 6 6 6 6 6 5 6 7 5 5 6 5 5 5 5 6 6 5 6 5
 5 5 5 6 5 6 6 6 5 6 5 6 5 5 5 6 5 5 6 6 6 5 5 6 6 5 5 6 5 6 6 5 6 5 5 6 6
 6 6 6 6 5 6 6 5 5 5 6 5 5 5 5 6 5 6 6 6 6 6 6 5 6 6]
DecisionTree
[ 88.31990794  87.22669735  87.51438435  87.28423475  88.37744534
  85.84579977  86.70886076  87.39930955  86.93901036  86.65132336
  88.20483314  86.53624856  88.55005754  88.03222094  87.11162255
  87.28423475  87.39930955  87.39930955  87.39930955  86.93901036
  87.22669735  88.03222094  86.93901036  87.62945915  88.31990794
  87.45684695  86.36363636  88.43498274  86.19102417  85.04027618
  86.70886076  87.97468354  86.53624856  87.28423475  87.45684695
  87.62945915  87.45684695  86.70886076  86.70886076  86.88147296
  86.30609896  86.30609896  87.74453395  88.26237054  87.22669735
  86.70886076  86.65132336  86.19102417  87.91714614  88.43498274
  86.53624856  87.05408516  87.28423475  87.05408516  86.42117376
  87.68699655  87.74453395  87.22669735  86.99654776  86.93901036
  88.31990794  87.22669735  87.85960875  86.42117376  88.14729574
  86.13348677  87.05408516  87.57192175  86.36363636  87.57192175
  86.42117376  87.62945915  87.68699655  87.85960875  86.82393556
  88.49252014  87.80207135  88.37744534  87.34177215  87.62945915
  87.74453395  88.78020713  87.57192175  86.99654776  88.20483314
  87.45684695  87.57192175  87.80207135  86.24856157  87.05408516
  85.73072497  87.80207135  88.20483314  88.14729574  88.14729574
  87.51438435  87.80207135  84.81012658  90.44879171  86.93901036]
87.33
0.82
[5 6 6 6 5 6 5 5 5 6 6 6 5 5 6 6 6 5 5 5 5 5 6 5 5 6 6 5 6 7 6 6 5 5 6 5 5
 6 6 6 5 6 5 5 5 6 5 7 5 6 6 6 5 6 6 5 5 5 6 6 5 5 6 6 5 6 5 5 6 5 6 6 5 5
 5 5 5 5 6 5 5 6 6 6 5 6 6 6 6 5 6 5 5 5 5 5 5 7 4 5]
k-NN
[ 82.10586881  84.06214039  80.66743383  81.76064442  79.74683544
  83.0264672   84.06214039  81.41542002  81.24280783  82.56616801
  80.49482163  81.41542002  83.5443038   81.47295742  81.76064442
  82.27848101  81.76064442  82.85385501  82.85385501  81.70310702
  83.94706559  81.30034522  81.41542002  82.10586881  81.30034522
  81.93325662  82.56616801  81.76064442  81.47295742  81.30034522
  81.93325662  82.16340621  79.74683544  81.35788262  80.84004603
  81.76064442  81.81818182  81.47295742  80.49482163  81.70310702
  81.99079402  81.81818182  80.89758343  82.39355581  83.2566168
  82.79631761  84.06214039  81.53049482  81.30034522  80.78250863
  81.30034522  82.45109321  78.82623705  79.80437284  84.17721519
  81.01265823  84.52243959  80.43728423  80.78250863  81.99079402
  80.78250863  81.99079402  81.41542002  82.33601841  82.50863061
  83.4867664   81.47295742  81.93325662  81.64556962  81.99079402
  82.79631761  80.95512083  80.37974684  83.94706559  83.4867664
  83.1990794   81.70310702  83.2566168   82.91139241  81.07019563
  82.04833142  81.47295742  81.07019563  82.45109321  82.10586881
  80.55235903  82.45109321  80.89758343  82.22094361  81.76064442
  82.73878021  82.04833142  79.40161105  81.58803222  81.76064442
  81.81818182  82.10586881  82.9689298   82.85385501  82.16340621]
81.89
1.07
[ 8  8  9  9  9  8  8  9 10  8  9  9  8  9  8  9 10  8  9  9  8 10  9  8  9
  9  9  9  9  9  9  9  9  9  9  9  9  9  8  8  8  8  9  8  8  8  8 10  9 10
  8  8 10 10  9  8  8  9  9  9 10  9  9  8  9  8  9  8  9  9  8 10  9  8  8
  8 10  8  8  9  9  9  9  8  8 10  8  9  9  9  9  9  9  9  9  9  9  8  8  8]
LogisticRegression
[ 90.10356732  90.73647871  89.35558113  90.79401611  90.50632911
  91.08170311  89.70080552  90.04602992  89.70080552  90.33371692
  90.33371692  90.27617952  90.56386651  89.70080552  89.87341772
  90.67894131  90.10356732  89.06789413  89.64326812  89.18296893
  90.27617952  90.90909091  90.62140391  90.67894131  90.90909091
  90.85155351  90.90909091  90.67894131  89.87341772  89.64326812
  90.39125432  91.6570771   88.89528193  89.24050633  90.73647871
  89.98849252  90.96662831  89.87341772  90.85155351  89.47065593
  89.01035673  90.44879171  90.04602992  89.64326812  90.27617952
  90.44879171  91.08170311  90.27617952  89.01035673  91.19677791
  89.24050633  90.79401611  89.47065593  89.75834292  90.67894131
  89.41311853  90.10356732  89.47065593  90.44879171  89.87341772
  89.47065593  90.50632911  89.81588032  89.35558113  90.33371692
  89.98849252  89.87341772  88.95281933  89.47065593  90.67894131
  91.6570771   90.96662831  90.73647871  90.56386651  90.04602992
  90.10356732  89.87341772  90.21864212  90.27617952  90.79401611
  90.33371692  89.93095512  90.10356732  90.04602992  90.50632911
  90.90909091  90.50632911  89.87341772  90.50632911  90.62140391
  90.04602992  90.10356732  89.47065593  90.73647871  90.79401611
  91.8296893   89.70080552  91.3693901   90.50632911  89.81588032]
90.21
0.62
[3 3 3 3 3 2 3 3 4 3 3 4 3 3 3 3 3 3 4 4 4 2 2 3 3 2 3 3 4 4 2 2 4 4 2 4 2
 2 2 3 4 2 3 3 3 3 2 2 4 3 4 3 4 3 2 4 4 4 4 3 4 3 3 4 3 3 3 4 3 3 2 2 2 3
 3 4 3 3 3 2 3 3 3 3 4 3 4 4 3 3 2 4 3 3 2 3 3 2 3 3]
MultinomialNB
[ 79.28653625  81.18527043  78.99884925  80.49482163  78.71116226
  80.20713464  80.20713464  79.91944764  81.41542002  80.43728423
  79.34407365  80.32220944  80.55235903  79.28653625  80.09205984
  79.80437284  82.33601841  80.09205984  80.20713464  79.91944764
  79.05638665  83.1990794   80.49482163  79.97698504  80.84004603
  80.72497123  81.70310702  80.72497123  81.01265823  80.55235903
  80.84004603  81.47295742  79.17146145  80.66743383  79.57422325
  79.97698504  81.76064442  80.14959724  78.53855006  78.25086306
  78.42347526  79.91944764  80.32220944  80.78250863  81.41542002
  80.37974684  78.71116226  83.6018412   79.86191024  80.95512083
  78.71116226  79.97698504  80.37974684  80.26467204  82.22094361
  79.34407365  81.41542002  78.65362486  79.40161105  81.18527043
  81.12773303  80.84004603  79.86191024  79.28653625  81.12773303
  80.26467204  80.66743383  80.03452244  79.51668585  81.64556962
  79.74683544  81.81818182  80.09205984  80.72497123  79.80437284
  80.72497123  82.10586881  80.95512083  80.26467204  80.66743383
  81.53049482  80.60989643  80.55235903  79.11392405  80.03452244
  81.07019563  80.89758343  80.37974684  80.26467204  81.01265823
  81.35788262  81.35788262  79.40161105  80.78250863  80.55235903
  80.95512083  80.49482163  81.47295742  81.58803222  79.45914845]
80.42
0.98
[10 10 10 10 10 10 10 10  9 10 10 10 10 10 10 10  9 10 10 10 10  9 10 10 10
 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  9 10  9
 10 10  9  9 10 10 10 10 10 10  9 10 10 10 10 10 10 10 10 10 10  9 10 10 10
 10  9 10 10 10 10 10 10 10 10  9 10 10 10 10 10 10  9 10 10 10 10 10  9 10]
BernoulliNB
[ 80.78250863  83.716916    81.41542002  84.00460299  82.04833142
  82.62370541  83.1990794   82.16340621  82.04833142  82.56616801
  80.89758343  82.62370541  83.0264672   82.33601841  81.58803222
  82.68124281  83.429229    81.41542002  83.141542    82.50863061
  81.93325662  84.23475259  82.56616801  81.70310702  83.2566168
  82.56616801  83.4867664   82.27848101  83.77445339  83.0264672
  82.56616801  83.0264672   81.35788262  81.99079402  81.70310702
  82.22094361  82.91139241  81.99079402  80.37974684  80.26467204
  81.81818182  81.30034522  81.58803222  81.99079402  82.39355581
  82.73878021  81.76064442  84.17721519  81.87571922  82.79631761
  81.30034522  81.76064442  81.47295742  82.10586881  84.63751438
  80.89758343  83.4867664   81.30034522  80.95512083  82.45109321
  82.79631761  82.45109321  82.45109321  82.10586881  84.06214039
  83.3141542   83.3141542   81.70310702  82.33601841  83.6018412
  81.24280783  83.6018412   82.73878021  82.04833142  82.68124281
  82.45109321  83.429229    83.0840046   81.64556962  82.9689298
  83.4867664   83.6018412   82.39355581  81.64556962  82.10586881
  83.2566168   81.76064442  82.39355581  82.73878021  84.06214039
  83.716916    83.6593786   80.66743383  82.68124281  83.0840046
  82.68124281  82.91139241  82.27848101  81.47295742  81.76064442]
82.45
0.91
[ 9  9  8  8  8  9  9  8  8  8  8  8  9  8  9  8  8  9  8  8  9  8  8  9  8
  8  8  8  8  8  8  8  8  8  8  8  8  8  9  9  9  9  8  9  9  9  9  8  8  8
  8  9  8  8  8  9  9  8  8  8  8  8  8  9  8  9  8  9  8  8  9  8  8  9  9
  9  8  9  9  8  8  8  8  9  8  8  9  8  8  8  8  8  8  8  8  8  8  9 10  9]
AdaBoost
[ 84.46490219  85.44303797  86.36363636  85.96087457  86.93901036
  84.52243959  84.23475259  85.15535098  85.90333717  85.09781358
  83.77445339  84.57997699  84.86766398  85.55811277  84.98273878
  85.78826237  85.61565017  85.32796318  85.50057537  84.52243959
  84.69505178  85.04027618  84.57997699  86.42117376  87.51438435
  86.88147296  84.57997699  85.27042578  85.96087457  85.38550058
  85.27042578  85.96087457  84.57997699  84.00460299  86.53624856
  85.09781358  84.63751438  85.09781358  83.6018412   83.429229
  84.40736479  84.63751438  85.32796318  85.27042578  84.69505178
  85.21288838  84.57997699  86.65132336  84.46490219  85.73072497
  84.69505178  83.88952819  85.21288838  85.90333717  85.21288838
  84.52243959  85.67318757  85.38550058  85.96087457  85.67318757
  85.67318757  85.32796318  84.81012658  85.84579977  86.82393556
  85.38550058  84.75258918  84.46490219  85.15535098  85.15535098
  85.04027618  84.86766398  84.34982739  85.61565017  84.34982739
  85.90333717  86.93901036  85.32796318  85.67318757  85.27042578
  85.21288838  85.84579977  85.96087457  85.78826237  83.1990794
  85.21288838  86.76639816  85.04027618  84.52243959  84.92520138
  85.61565017  85.61565017  84.29228999  86.24856157  85.21288838
  85.55811277  84.75258918  84.98273878  85.15535098  83.83199079]
85.23
0.80
[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 6 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7
 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7]
RandomForest
[ 91.9447641   90.33371692  90.90909091  91.4269275   91.19677791
  90.96662831  89.93095512  90.79401611  90.67894131  91.08170311
  90.62140391  90.85155351  91.08170311  91.8296893   90.27617952
  91.4269275   91.02416571  90.73647871  91.13924051  91.19677791
  91.4844649   90.62140391  90.10356732  91.6570771   91.8872267
  90.85155351  91.19677791  91.5995397   90.16110472  90.50632911
  89.75834292  91.4844649   90.10356732  89.93095512  90.33371692
  90.79401611  90.90909091  89.52819333  90.16110472  89.75834292
  90.16110472  89.64326812  90.39125432  90.56386651  91.4269275
  90.73647871  90.85155351  89.64326812  91.5995397   91.5420023
  90.67894131  92.0598389   90.56386651  90.96662831  90.56386651
  90.85155351  90.44879171  89.58573072  90.85155351  91.08170311
  92.17491369  91.13924051  90.50632911  89.75834292  91.13924051
  91.08170311  91.19677791  90.56386651  90.21864212  91.6570771
  90.96662831  90.96662831  90.56386651  90.85155351  90.90909091
  92.0598389   91.8296893   91.5995397   91.9447641   90.16110472
  91.08170311  92.40506329  90.21864212  91.5420023   91.4269275
  91.3693901   91.8872267   90.39125432  90.56386651  91.4269275
  88.66513234  92.40506329  90.67894131  90.50632911  90.62140391
  91.4844649   91.13924051  89.47065593  91.7146145   90.73647871]
90.88
0.70
[2 4 2 2 2 3 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 3 4 2 2 2 2 2 2 2 4 3 2 2 3 2 3
 4 4 2 2 4 2 2 2 2 3 4 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 4 2
 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 4 2 2 4 3 4 2 4 2 2]

<bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)>
<bound method LinearSVC.get_params of LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,
     verbose=0)>
<bound method SVC.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)>
<bound method DecisionTreeClassifier.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')>
<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')>
<bound method LogisticRegression.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)>
<bound method MultinomialNB.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>
<bound method BernoulliNB.get_params of BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)>
<bound method AdaBoostClassifier.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)>
<bound method RandomForestClassifier.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)>
