89.596333 minutes
PU1_500_Tuned:
Emails: 1099
Words: 500
Ham: 618
Spam: 481

MLP
[ 98.18181818  95.          96.81818182  95.45454545  95.45454545
  95.45454545  97.27272727  96.36363636  97.27272727  96.81818182
  96.81818182  98.18181818  96.81818182  97.72727273  96.81818182
  98.18181818  97.72727273  95.45454545  98.18181818  94.54545455
  95.45454545  97.72727273  98.63636364  95.90909091  97.27272727
  94.54545455  95.90909091  96.36363636  95.          95.90909091
  98.63636364  99.09090909  96.81818182  96.81818182  97.27272727
  98.63636364  97.72727273  97.72727273  95.45454545  97.72727273
  96.81818182  98.18181818  97.72727273  98.18181818  98.18181818
  95.90909091  95.45454545  95.90909091  95.90909091  97.27272727
  96.36363636  96.81818182  97.27272727  97.27272727  96.81818182
  96.81818182  95.90909091  96.81818182  98.63636364  95.90909091
  98.18181818  98.63636364  98.18181818  96.81818182  96.36363636
  95.45454545  97.72727273  96.81818182  99.54545455  95.90909091
  97.27272727  98.18181818  97.72727273  96.36363636  95.90909091
  97.27272727  98.63636364  97.27272727  96.81818182  97.27272727
  96.36363636  96.81818182  96.36363636  95.          97.72727273
  96.81818182  96.36363636  95.90909091  95.          95.45454545
  96.81818182  97.72727273  96.81818182  97.27272727  95.45454545
  96.36363636  95.45454545  96.36363636  96.81818182  95.45454545]
96.84
1.09
[1 3 2 3 3 3 1 1 3 3 2 1 3 2 1 1 2 4 2 3 2 2 1 4 1 3 3 3 3 4 2 1 2 4 2 2 1
 2 3 1 3 1 2 1 1 4 3 4 2 1 4 3 3 1 4 3 3 3 2 3 1 1 1 2 3 3 3 1 1 3 1 1 2 3
 3 5 1 1 3 1 3 3 3 3 2 2 1 4 3 4 3 2 1 1 2 2 3 3 2 4]
LinearSVC
[ 95.          92.72727273  94.54545455  95.45454545  94.54545455  95.
  97.27272727  95.          95.45454545  96.81818182  95.          95.
  95.90909091  98.18181818  96.81818182  94.54545455  95.          96.81818182
  97.27272727  94.09090909  92.27272727  97.27272727  96.36363636
  93.18181818  95.90909091  94.09090909  94.09090909  95.90909091
  93.63636364  97.27272727  97.72727273  96.81818182  95.45454545
  96.36363636  94.54545455  97.27272727  95.90909091  95.45454545
  93.63636364  96.81818182  94.09090909  95.90909091  96.81818182
  97.72727273  95.90909091  95.90909091  95.          96.36363636
  95.45454545  94.54545455  96.81818182  95.90909091  96.81818182
  95.45454545  97.72727273  93.63636364  95.          95.90909091
  96.36363636  95.90909091  95.90909091  96.81818182  97.27272727
  96.36363636  94.54545455  95.45454545  95.45454545  94.09090909
  96.36363636  95.90909091  96.81818182  96.81818182  96.81818182
  95.90909091  95.45454545  97.27272727  95.90909091  95.          94.54545455
  96.81818182  95.45454545  93.63636364  95.90909091  91.81818182
  97.27272727  94.09090909  96.36363636  95.45454545  93.63636364
  94.54545455  95.45454545  96.81818182  94.54545455  94.54545455
  93.63636364  92.72727273  95.90909091  95.          93.63636364
  95.90909091]
95.54
1.31
[6 6 6 3 5 5 1 5 5 3 5 6 5 1 1 6 5 3 3 4 6 3 5 6 4 4 4 5 5 1 5 5 5 6 5 5 4
 6 6 3 5 3 5 3 4 4 5 2 5 4 1 5 4 6 2 5 4 6 5 3 4 5 4 3 6 3 6 6 4 3 4 4 4 4
 4 5 5 4 6 3 4 6 4 5 3 6 1 5 7 6 5 4 4 6 4 6 2 6 6 2]
SVC
[ 97.72727273  93.63636364  95.          94.09090909  95.          95.45454545
  95.45454545  96.36363636  95.90909091  95.90909091  95.          95.45454545
  95.45454545  96.81818182  96.36363636  95.90909091  94.54545455
  94.54545455  97.27272727  91.81818182  93.18181818  95.          95.
  95.90909091  94.54545455  92.27272727  93.63636364  96.36363636
  93.18181818  92.72727273  98.18181818  97.27272727  95.45454545
  97.72727273  94.54545455  96.81818182  95.45454545  96.36363636
  94.54545455  95.          93.18181818  94.09090909  96.36363636
  96.81818182  95.90909091  96.36363636  95.          94.54545455
  94.54545455  94.09090909  95.45454545  95.          93.63636364
  96.36363636  95.90909091  93.18181818  94.09090909  96.36363636
  95.90909091  94.54545455  94.54545455  97.72727273  96.81818182  95.
  95.90909091  93.63636364  95.90909091  95.          95.45454545
  94.54545455  96.81818182  96.81818182  95.45454545  95.          95.
  97.72727273  95.45454545  93.18181818  96.36363636  93.63636364
  94.09090909  94.54545455  95.45454545  90.90909091  96.36363636  95.
  94.09090909  94.09090909  95.          95.          95.45454545
  95.45454545  94.09090909  95.45454545  92.72727273  93.18181818
  93.18181818  95.45454545  94.54545455  95.        ]
95.11
1.36
[2 5 4 6 4 3 5 1 4 5 5 5 6 5 3 5 6 5 3 8 5 6 6 4 6 6 5 3 6 6 4 4 5 1 5 6 5
 4 4 5 6 5 6 5 4 3 5 6 6 5 6 6 6 5 6 6 5 5 6 6 6 3 5 6 5 6 5 5 6 6 4 4 6 5
 5 2 6 6 5 6 6 5 6 6 6 5 6 6 3 5 5 5 6 5 6 5 6 5 5 5]
DecisionTree
[ 90.          88.18181818  90.90909091  90.90909091  89.54545455
  93.63636364  90.          90.90909091  93.18181818  93.18181818
  89.54545455  90.90909091  90.          91.36363636  89.09090909
  90.90909091  91.36363636  91.81818182  88.63636364  93.18181818
  89.54545455  88.63636364  91.81818182  90.45454545  92.27272727
  90.45454545  88.18181818  91.36363636  93.18181818  90.          92.72727273
  89.54545455  90.90909091  91.36363636  88.63636364  91.81818182
  92.27272727  92.72727273  90.          90.45454545  89.09090909
  90.45454545  90.45454545  89.09090909  88.63636364  90.45454545
  88.18181818  83.63636364  89.54545455  90.90909091  91.81818182
  91.81818182  92.72727273  90.90909091  93.18181818  89.09090909
  88.18181818  88.63636364  95.          92.27272727  90.          94.09090909
  91.81818182  91.81818182  90.          92.72727273  88.63636364
  88.18181818  92.27272727  90.          90.90909091  88.18181818
  92.27272727  88.63636364  85.90909091  91.36363636  90.90909091
  89.09090909  88.63636364  92.27272727  89.54545455  87.72727273  90.
  89.54545455  90.          88.63636364  89.54545455  87.27272727
  94.09090909  92.27272727  91.81818182  91.36363636  90.45454545
  89.54545455  89.09090909  90.90909091  88.63636364  89.54545455
  92.27272727  87.72727273]
90.45
1.85
[10  9 10  7  8  7  8  9  9  7  8  9  9  7  8  7  7  7  9  6  9 10  8  7  7
  8 10  8  6  9  7  9  7  8  9  9  8  7  7  8  9  8  9  9 10  9 10 10  9  7
  7  7  7  7  7  9 10  9  7  7 10  7  7  8  7  7 10  9  8  8  7  9  7  9  9
  7  7  8  9  8  9  9  7  8  9  9  9 10  6  8  9  7  8  9  9  8  9  9  7  9]
k-NN
[ 90.45454545  90.90909091  93.18181818  87.27272727  89.09090909
  92.72727273  86.36363636  91.81818182  93.63636364  90.90909091
  89.54545455  92.27272727  90.90909091  90.45454545  88.63636364  90.
  90.45454545  90.45454545  94.09090909  90.          90.45454545
  90.45454545  89.54545455  90.45454545  91.36363636  90.          89.09090909
  87.72727273  88.63636364  88.18181818  86.36363636  90.45454545
  90.90909091  92.72727273  89.09090909  92.72727273  88.63636364  90.
  86.81818182  88.63636364  90.45454545  88.18181818  92.27272727
  90.45454545  91.36363636  92.27272727  90.45454545  88.63636364
  88.18181818  88.18181818  90.90909091  87.72727273  91.36363636  90.          90.
  92.27272727  94.09090909  90.          90.          90.45454545
  91.36363636  89.54545455  88.63636364  89.09090909  89.54545455  85.
  91.81818182  90.          93.18181818  88.18181818  90.90909091  90.
  89.09090909  89.09090909  89.09090909  90.90909091  89.09090909
  86.81818182  90.          92.27272727  90.          91.81818182  90.
  86.81818182  90.45454545  91.81818182  90.          91.81818182
  91.81818182  94.09090909  94.09090909  89.09090909  90.          90.90909091
  90.45454545  88.18181818  90.          91.81818182  92.27272727
  89.54545455]
90.21
1.81
[ 9  8  7  8  9  8  9  8  7  8  8  8  7  8  9  8  9  8  7  9  8  9  9  7  9
  9  8 10  9 10 10  8  7  7  8  8  9  8  9  9  7 10  7  8  8  7  8  7 10  9
  8  9  9  9  9  7  5  8 10  8  8 10 10  9  8 10  7  8  7  9  7  8  9  7  8
  8  9 10  8  8  8  8  7 10  8  7  8  7  8  7  7  9  9  8  8  9  8  8  7  8]
LogisticRegression
[ 97.27272727  95.          95.          95.          94.54545455  95.
  95.45454545  95.          95.45454545  95.90909091  96.36363636
  96.81818182  96.36363636  97.27272727  96.36363636  96.81818182
  97.27272727  94.54545455  96.36363636  93.18181818  95.          96.36363636
  97.27272727  96.81818182  95.          93.18181818  92.72727273
  97.72727273  94.09090909  94.54545455  98.63636364  98.18181818
  96.81818182  97.72727273  95.45454545  97.72727273  96.36363636
  95.90909091  94.09090909  96.81818182  95.90909091  95.45454545
  97.27272727  97.72727273  95.90909091  95.90909091  95.45454545
  96.36363636  95.90909091  94.09090909  95.90909091  96.81818182
  95.90909091  97.27272727  96.36363636  94.54545455  94.09090909
  96.81818182  96.81818182  95.          95.90909091  97.72727273
  96.36363636  96.36363636  97.27272727  95.45454545  96.81818182
  96.36363636  96.36363636  95.90909091  97.27272727  97.72727273
  96.36363636  94.54545455  95.          97.72727273  96.81818182  95.
  96.81818182  96.81818182  95.45454545  95.          95.90909091
  92.72727273  98.18181818  95.45454545  96.36363636  96.36363636
  94.54545455  96.36363636  96.81818182  98.18181818  94.54545455
  96.36363636  93.63636364  94.09090909  95.          95.90909091
  96.36363636  95.90909091]
95.97
1.25
[4 3 4 5 5 5 5 5 5 5 4 4 4 3 3 4 3 5 5 6 3 5 3 3 5 5 6 1 4 5 2 2 2 1 4 4 2
 5 5 3 4 4 4 3 4 4 3 2 2 5 5 3 5 1 5 4 5 3 4 5 4 3 6 3 1 3 4 4 4 3 1 3 5 6
 5 2 4 4 3 3 4 4 4 4 1 4 1 2 5 2 3 1 4 4 4 4 4 4 4 2]
MultinomialNB
[ 91.36363636  91.81818182  93.18181818  86.81818182  92.72727273
  89.54545455  91.36363636  92.27272727  93.63636364  88.18181818
  92.27272727  94.09090909  90.45454545  89.09090909  90.90909091
  89.09090909  91.36363636  90.45454545  92.72727273  93.63636364
  91.36363636  91.36363636  94.09090909  88.18181818  92.27272727
  87.72727273  89.09090909  93.18181818  91.36363636  90.90909091
  90.45454545  93.18181818  88.63636364  91.36363636  91.36363636
  94.54545455  94.09090909  90.          89.09090909  95.          90.
  91.81818182  89.09090909  95.          92.27272727  91.36363636
  92.72727273  87.72727273  90.90909091  89.54545455  90.90909091
  91.36363636  92.27272727  90.45454545  91.81818182  90.45454545
  93.63636364  90.90909091  90.45454545  89.54545455  90.90909091
  93.63636364  89.54545455  92.27272727  89.09090909  91.36363636  90.
  90.90909091  91.36363636  91.81818182  90.          94.09090909
  91.36363636  89.09090909  93.63636364  89.09090909  90.90909091
  93.18181818  90.90909091  93.18181818  92.27272727  93.18181818
  89.09090909  90.90909091  93.18181818  91.36363636  92.72727273
  90.90909091  90.45454545  90.          93.18181818  90.90909091
  91.81818182  91.81818182  91.36363636  92.27272727  92.27272727
  92.27272727  89.09090909  91.36363636]
91.31
1.71
[ 7  7  7  9  7  9  7  7  7  9  7  7  8  9  7 10  7  8  8  5  7  7  7  9  7
 10  8  7  8  7  8  7  9  8  7  7  7  8  8  5  8  7 10  7  7  8  7  8  7  8
  8  8  8  8  8  8  8  7  9  9  9  8  9  7  9  8  8  7 10  7  9  7  8  7  7
  9  7  6  7  7  7  7  9  6  7  8  7  8  9  9  8  8  7  7  7  7  7  7  9  7]
BernoulliNB
[ 91.36363636  84.54545455  91.81818182  86.36363636  84.09090909
  86.81818182  85.45454545  86.36363636  86.81818182  85.          85.90909091
  89.09090909  90.          85.          83.63636364  90.          85.45454545
  86.81818182  84.54545455  86.81818182  81.36363636  90.90909091
  89.09090909  85.          87.27272727  91.81818182  90.90909091
  88.18181818  85.90909091  90.90909091  88.63636364  86.81818182
  84.54545455  87.27272727  87.27272727  90.45454545  85.45454545
  83.63636364  85.45454545  81.81818182  89.09090909  89.09090909
  92.27272727  87.72727273  89.54545455  89.09090909  89.54545455  85.          90.
  87.27272727  86.81818182  85.90909091  85.          85.          89.09090909
  86.81818182  91.81818182  82.72727273  91.81818182  88.63636364
  92.27272727  90.45454545  90.90909091  87.72727273  86.81818182
  85.90909091  89.09090909  85.90909091  92.27272727  82.27272727
  82.72727273  86.81818182  86.81818182  87.72727273  84.09090909
  86.36363636  87.27272727  87.27272727  84.09090909  90.          86.81818182
  87.27272727  85.45454545  89.09090909  84.09090909  84.09090909
  88.18181818  87.72727273  82.72727273  87.72727273  87.27272727
  88.63636364  85.          85.          89.09090909  85.          83.63636364
  87.72727273  88.63636364  84.54545455]
87.15
2.60
[ 7 10  9 10 10 10 10 10 10 10 10 10  9 10 10  8 10 10 10 10 10  8 10 10 10
  7  7  9 10  7  9 10 10 10 10 10 10 10 10 10  9  9  7 10  9 10  9  9  8 10
 10 10 10 10 10 10  9 10  8 10  7  9  8 10 10  9  9 10  8 10 10 10 10 10 10
 10 10  9 10 10 10 10 10  9 10 10 10  9 10 10 10 10 10 10  9 10 10 10 10 10]
AdaBoost
[ 97.72727273  95.45454545  96.81818182  95.90909091  96.81818182
  98.18181818  96.36363636  96.36363636  97.72727273  97.27272727
  96.81818182  97.72727273  98.63636364  97.27272727  96.36363636
  97.72727273  96.81818182  97.27272727  96.36363636  97.27272727
  94.09090909  96.81818182  97.72727273  97.27272727  96.36363636
  95.45454545  96.36363636  95.          95.90909091  96.36363636
  97.72727273  96.36363636  96.81818182  97.72727273  96.81818182
  98.63636364  95.45454545  97.27272727  96.36363636  97.27272727
  98.18181818  94.09090909  97.72727273  96.81818182  96.36363636
  98.18181818  98.18181818  95.45454545  96.81818182  97.27272727
  96.81818182  97.72727273  98.63636364  96.81818182  98.63636364
  98.18181818  96.36363636  98.18181818  99.09090909  98.18181818
  97.72727273  96.36363636  98.18181818  97.27272727  96.81818182
  96.81818182  98.63636364  96.81818182  98.18181818  97.27272727
  96.36363636  96.81818182  97.72727273  97.72727273  96.36363636
  97.72727273  98.63636364  95.45454545  97.27272727  95.45454545
  97.72727273  97.72727273  96.81818182  95.45454545  97.27272727
  96.81818182  95.90909091  96.36363636  96.81818182  95.90909091
  98.18181818  95.45454545  96.81818182  97.27272727  94.54545455
  97.27272727  97.27272727  96.81818182  96.81818182  96.81818182]
96.98
1.01
[2 2 2 2 2 1 4 1 2 1 2 2 1 3 3 2 4 2 5 1 4 4 2 2 2 2 2 6 2 2 5 6 2 1 3 2 5
 3 2 2 1 5 2 5 3 1 1 5 1 1 1 1 1 4 1 1 2 1 1 2 2 6 1 1 2 1 2 1 3 1 6 4 2 2
 2 2 1 3 1 5 1 2 2 2 3 2 5 2 2 3 1 5 1 1 3 1 1 2 2 1]
RandomForest
[  97.27272727   95.90909091   98.63636364   97.27272727   97.72727273
   98.18181818   96.81818182   96.36363636   98.18181818   97.27272727
   98.18181818   97.72727273   97.27272727   96.81818182   96.36363636
   97.27272727   98.18181818   97.72727273   99.54545455   97.27272727
   95.90909091   98.63636364   97.27272727   97.72727273   96.36363636
   97.72727273   97.72727273   96.81818182   97.72727273   96.36363636
   99.09090909   97.72727273   97.27272727   96.81818182   98.18181818
   99.54545455   96.36363636   98.63636364   96.81818182   95.
   97.72727273   97.27272727   98.18181818   98.18181818   98.18181818
   98.18181818   96.36363636   96.81818182   95.90909091   96.36363636
   96.81818182   97.27272727   98.18181818   97.27272727   97.72727273
   97.72727273   97.72727273   97.72727273   98.63636364   98.63636364
   97.72727273   98.18181818   97.72727273   96.36363636   96.36363636
   96.81818182  100.           96.81818182   99.09090909   96.36363636
   97.27272727   98.18181818   98.18181818   99.09090909   97.27272727
   98.63636364   98.63636364   97.27272727   97.27272727   97.27272727
   97.27272727   98.18181818   98.18181818   96.81818182   97.27272727
   97.27272727   96.36363636   96.81818182   97.72727273   97.27272727
   98.18181818   97.27272727   96.81818182   97.27272727   98.18181818
   95.45454545   94.09090909   98.18181818   98.18181818   95.        ]
97.45
0.99
[4 1 1 1 1 1 3 1 1 1 1 2 2 5 3 3 1 1 1 1 1 1 3 1 2 1 1 2 1 2 1 3 1 4 1 1 2
 1 1 5 2 2 1 1 1 1 2 1 2 3 1 2 2 1 2 2 1 2 2 1 2 2 3 3 3 1 1 1 2 2 1 1 1 1
 1 1 1 1 1 1 2 1 1 1 3 1 1 1 1 1 1 3 1 1 1 3 5 1 1 5]

MLP
Number of parameters combination: 16
LinearSVC
Number of parameters combination: 8
SVC
Number of parameters combination: 24
DecisionTree
Number of parameters combination: 72
k-NN
Number of parameters combination: 96
LogisticRegression
Number of parameters combination: 40
MultinomialNB
Number of parameters combination: 12
BernoulliNB
Number of parameters combination: 72
AdaBoost
Number of parameters combination: 50
RandomForest
Number of parameters combination: 72

<bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(500,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=100000, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)>
<bound method LinearSVC.get_params of LinearSVC(C=0.5, class_weight=None, dual=False, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,
     verbose=0)>
<bound method SVC.get_params of SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovo', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)>
<bound method DecisionTreeClassifier.get_params of DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=True, random_state=None,
            splitter='best')>
<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=1,
           weights='distance')>
<bound method LogisticRegression.get_params of LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100000, multi_class='ovr',
          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',
          tol=0.0001, verbose=0, warm_start=False)>
<bound method MultinomialNB.get_params of MultinomialNB(alpha=1e-10, class_prior=None, fit_prior=False)>
<bound method BernoulliNB.get_params of BernoulliNB(alpha=1e-10, binarize=0.0, class_prior=None, fit_prior=True)>
<bound method AdaBoostClassifier.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=0.1, n_estimators=500, random_state=None)>
<bound method RandomForestClassifier.get_params of RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',
            max_depth=None, max_features='log2', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)>
