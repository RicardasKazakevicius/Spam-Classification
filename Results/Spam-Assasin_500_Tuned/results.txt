533.639450 minutes
Spam-Assasin_500_Tuned:
Emails: 6046
Words: 500
Ham: 4150
Spam: 1896

MLP
[ 89.91735537  90.90909091  92.14876033  90.99173554  91.40495868
  91.98347107  93.47107438  91.48760331  91.23966942  91.81818182
  91.48760331  91.15702479  91.65289256  92.47933884  92.23140496
  92.80991736  91.65289256  91.32231405  92.47933884  92.56198347
  92.80991736  92.47933884  92.72727273  90.24793388  90.82644628
  92.0661157   91.23966942  90.24793388  91.32231405  91.90082645
  90.90909091  90.          90.66115702  90.74380165  91.40495868
  92.89256198  91.32231405  92.31404959  91.07438017  91.32231405
  90.24793388  91.32231405  91.40495868  90.33057851  91.65289256
  90.41322314  90.5785124   91.32231405  91.15702479  91.40495868
  92.23140496  91.32231405  91.40495868  90.16528926  90.90909091
  90.66115702  89.91735537  90.08264463  90.33057851  90.08264463
  89.83471074  89.4214876   90.24793388  92.23140496  91.98347107
  91.40495868  91.32231405  91.48760331  92.39669421  89.58677686
  91.48760331  91.15702479  91.65289256  91.15702479  90.41322314
  91.73553719  91.98347107  91.57024793  92.14876033  90.5785124
  91.57024793  92.31404959  91.23966942  91.48760331  91.98347107
  91.32231405  90.33057851  90.24793388  90.5785124   92.14876033
  90.82644628  91.15702479  91.15702479  91.23966942  93.2231405
  91.40495868  91.15702479  92.0661157   92.89256198  93.05785124]
91.36
0.86
[1 2 2 1 2 1 1 2 1 2 2 1 2 1 1 1 2 1 1 1 2 2 1 2 1 1 2 2 2 2 2 2 2 1 2 1 2
 2 2 2 2 1 1 1 2 2 2 2 2 2 1 1 2 2 2 2 2 1 2 2 2 2 2 1 1 1 1 2 1 2 2 1 2 2
 2 2 1 2 1 2 1 1 2 1 2 1 2 1 2 1 2 2 2 2 1 2 1 2 1 1]
LinearSVC
[ 88.51239669  88.51239669  90.24793388  87.76859504  90.33057851
  87.76859504  89.83471074  88.34710744  87.85123967  88.34710744
  88.34710744  88.09917355  89.00826446  88.59504132  87.3553719
  89.09090909  91.07438017  88.67768595  87.85123967  89.17355372
  90.49586777  89.50413223  90.5785124   87.10743802  88.59504132
  89.75206612  87.43801653  88.26446281  88.09917355  88.42975207
  87.76859504  88.09917355  88.92561983  88.01652893  87.60330579
  88.92561983  88.67768595  88.34710744  89.09090909  88.67768595
  89.09090909  87.60330579  89.00826446  89.09090909  88.92561983
  88.42975207  89.50413223  88.26446281  89.17355372  89.25619835
  88.84297521  88.67768595  89.09090909  87.85123967  87.43801653
  89.09090909  87.9338843   86.7768595   89.17355372  87.27272727
  86.36363636  88.42975207  86.7768595   89.83471074  88.84297521
  89.25619835  88.84297521  89.83471074  89.91735537  88.34710744
  89.09090909  88.59504132  88.01652893  88.09917355  87.19008264
  89.17355372  87.3553719   88.42975207  89.25619835  88.09917355
  87.85123967  89.17355372  88.84297521  88.51239669  89.75206612
  89.33884298  87.02479339  87.27272727  89.50413223  89.17355372  90.
  88.76033058  87.9338843   89.4214876   89.00826446  88.76033058
  88.42975207  88.26446281  89.09090909  89.50413223]
88.63
0.89
[4 4 3 4 3 4 3 5 6 6 5 5 5 5 5 5 4 4 5 6 6 4 4 5 4 3 4 5 6 5 5 3 5 4 5 4 7
 5 3 5 4 4 3 5 5 3 4 6 6 7 5 4 5 5 7 5 6 5 5 6 5 3 5 3 5 4 3 3 5 4 6 6 5 5
 5 5 4 5 4 5 4 3 6 4 6 4 6 7 3 4 4 4 5 4 5 3 4 5 6 5]
SVC
[ 88.51239669  88.42975207  90.24793388  87.85123967  90.24793388
  87.76859504  89.75206612  88.26446281  87.85123967  88.51239669
  88.01652893  88.26446281  89.09090909  88.51239669  87.3553719
  89.09090909  91.07438017  88.59504132  87.85123967  89.17355372
  90.5785124   89.50413223  90.41322314  87.02479339  88.51239669
  89.75206612  87.3553719   88.26446281  88.09917355  88.51239669
  87.76859504  88.09917355  88.84297521  87.9338843   87.43801653
  88.67768595  88.76033058  88.34710744  89.09090909  88.84297521
  89.00826446  87.60330579  88.92561983  89.09090909  89.09090909
  88.42975207  89.25619835  87.9338843   89.17355372  89.33884298
  88.84297521  88.76033058  88.92561983  87.85123967  87.52066116
  89.09090909  87.9338843   86.69421488  89.09090909  87.52066116
  86.19834711  88.42975207  86.7768595   89.75206612  88.76033058
  89.33884298  88.84297521  89.75206612  90.          88.26446281
  89.17355372  88.67768595  87.85123967  88.18181818  87.10743802
  89.09090909  87.3553719   88.51239669  89.17355372  88.09917355
  87.68595041  89.17355372  88.92561983  88.42975207  89.83471074
  89.17355372  87.02479339  87.3553719   89.50413223  89.17355372  90.
  88.67768595  87.9338843   89.33884298  89.00826446  88.51239669
  88.51239669  88.26446281  89.09090909  89.33884298]
88.61
0.89
[4 6 3 3 4 4 5 6 6 3 6 4 3 6 5 5 4 5 5 6 4 4 6 6 5 3 6 5 6 4 5 3 6 5 6 5 6
 5 3 4 6 4 4 5 3 3 6 7 6 6 5 3 7 5 5 5 6 6 6 5 6 3 5 5 6 3 3 5 4 5 4 5 7 4
 6 6 4 4 5 5 6 3 5 5 5 6 6 6 3 4 4 5 5 5 5 4 3 5 6 6]
DecisionTree
[ 85.45454545  84.87603306  86.69421488  87.43801653  86.19834711
  86.28099174  84.21487603  85.8677686   84.62809917  85.04132231
  85.53719008  87.02479339  86.03305785  87.76859504  85.45454545
  85.2892562   87.19008264  84.95867769  84.29752066  84.7107438
  84.46280992  85.04132231  85.78512397  85.61983471  85.04132231
  86.11570248  85.45454545  84.1322314   86.36363636  86.61157025
  87.43801653  84.38016529  84.79338843  85.95041322  84.46280992
  86.7768595   84.1322314   85.20661157  86.11570248  85.04132231
  85.20661157  83.88429752  86.03305785  83.63636364  83.88429752
  86.11570248  87.02479339  84.1322314   87.02479339  84.46280992
  86.69421488  86.03305785  87.10743802  86.94214876  85.70247934
  85.45454545  85.12396694  83.88429752  83.88429752  84.62809917
  85.04132231  84.38016529  85.70247934  86.19834711  85.45454545
  83.96694215  84.87603306  86.19834711  85.61983471  85.45454545
  84.79338843  85.37190083  86.19834711  85.53719008  85.2892562
  87.27272727  85.2892562   84.62809917  87.3553719   86.52892562
  85.04132231  86.19834711  87.3553719   85.12396694  85.78512397
  84.7107438   84.95867769  83.47107438  85.2892562   86.03305785
  86.03305785  87.19008264  84.79338843  86.11570248  87.02479339
  86.61157025  86.44628099  86.19834711  85.70247934  85.78512397]
85.58
1.01
[10 10 10  7  9  9  9  9 10  9 10  8  9  8  9  9  9 10 10  9  9  9  9  9  9
  9 10  9  9 10  8  9  9  8  9  9  9 10  9  9  9 10  9 10  9  9  9 10  9 10
  9  8  9  7 10 10 10  9 10  9  9 10  9  9 10 10 10  9 10  8  9 10 10 10  9
  9 10 10  9  8  8 10  7 10  9  9  9 10  9  9 10  9 10 10  8  9  8  9 10  9]
k-NN
[ 87.60330579  85.45454545  87.02479339  79.50413223  84.54545455
  85.20661157  83.38842975  84.46280992  86.7768595   84.62809917
  86.7768595   85.8677686   84.95867769  86.85950413  84.54545455
  83.2231405   83.80165289  85.61983471  87.52066116  83.55371901
  84.38016529  83.55371901  81.57024793  83.30578512  83.63636364
  82.6446281   87.3553719   82.56198347  85.70247934  87.52066116
  85.61983471  84.29752066  80.          84.7107438   83.55371901
  84.7107438   82.6446281   85.95041322  82.89256198  83.14049587
  82.80991736  85.2892562   85.78512397  85.37190083  82.39669421
  85.37190083  86.52892562  84.38016529  85.70247934  87.52066116
  85.61983471  81.40495868  86.19834711  85.53719008  86.11570248
  87.52066116  85.37190083  83.30578512  85.78512397  84.62809917
  83.55371901  85.45454545  84.87603306  86.11570248  86.36363636
  86.28099174  84.95867769  85.78512397  87.43801653  84.79338843
  84.79338843  85.8677686   87.19008264  86.7768595   84.29752066
  85.2892562   86.69421488  85.2892562   84.54545455  86.44628099
  82.97520661  86.52892562  85.70247934  85.95041322  81.57024793
  81.90082645  82.72727273  83.88429752  85.20661157  84.54545455
  87.68595041  85.45454545  85.70247934  86.36363636  83.96694215
  84.54545455  82.47933884  83.63636364  86.61157025  83.71900826]
84.88
1.70
[ 8  9  9 10 10 10 10 10  8 10  8 10 10 10 10 10 10  9  9 10 10 10 10 10 10
 10  6 10 10  8 10 10 10 10 10 10 10  9 10 10 10  9 10  9 10 10 10  9 10  9
 10 10 10 10  9  8  9 10  9  9 10  9 10 10  9  8  9 10  8 10  9  9  8  9 10
 10  7  9 10  9 10  9  9  9 10 10 10  9 10 10  8 10  9  9 10 10 10 10  9 10]
LogisticRegression
[ 88.67768595  88.59504132  89.75206612  87.76859504  90.08264463
  88.09917355  89.83471074  89.17355372  88.01652893  88.51239669
  88.59504132  87.68595041  89.09090909  89.00826446  87.9338843
  89.33884298  90.33057851  88.76033058  88.67768595  90.          90.5785124
  89.25619835  90.5785124   87.27272727  88.18181818  89.33884298
  87.43801653  88.59504132  88.67768595  88.42975207  88.18181818
  87.85123967  89.83471074  88.51239669  88.18181818  89.50413223
  89.66942149  89.17355372  88.51239669  88.34710744  89.09090909
  88.09917355  88.76033058  89.4214876   89.00826446  87.9338843
  89.4214876   88.51239669  89.4214876   89.83471074  89.25619835
  88.67768595  89.17355372  88.42975207  87.60330579  89.33884298
  88.92561983  86.94214876  89.33884298  88.76033058  86.44628099
  88.18181818  86.94214876  89.4214876   89.83471074  88.42975207
  88.76033058  89.83471074  90.49586777  88.59504132  89.58677686
  88.84297521  88.76033058  88.09917355  87.76859504  89.4214876
  87.68595041  88.84297521  89.33884298  88.18181818  88.34710744
  88.76033058  89.17355372  87.9338843   90.49586777  89.25619835
  88.34710744  87.43801653  89.33884298  89.50413223  90.08264463
  88.67768595  88.26446281  89.33884298  89.58677686  88.51239669
  88.01652893  88.34710744  89.4214876   89.83471074]
88.82
0.83
[3 3 6 4 5 3 3 3 5 3 3 7 3 3 4 4 6 3 4 4 4 6 4 4 6 5 4 4 4 5 3 5 3 3 3 3 4
 3 6 7 4 3 5 3 4 6 5 5 4 3 4 4 4 3 4 4 4 4 4 3 4 6 4 6 3 6 5 3 3 3 3 4 4 5
 4 4 3 3 3 4 3 5 4 7 4 5 3 5 5 3 3 5 4 5 4 4 6 4 4 3]
MultinomialNB
[ 87.9338843   87.76859504  88.42975207  87.27272727  89.4214876
  87.10743802  89.09090909  87.52066116  88.84297521  86.36363636
  88.01652893  88.09917355  87.43801653  89.00826446  87.10743802
  88.51239669  89.25619835  87.60330579  87.85123967  89.25619835
  89.33884298  88.76033058  89.25619835  88.09917355  87.43801653
  88.51239669  86.36363636  86.61157025  88.26446281  88.18181818
  86.61157025  86.69421488  87.43801653  87.3553719   87.27272727
  88.34710744  88.92561983  87.10743802  87.52066116  88.42975207
  88.67768595  86.11570248  87.76859504  88.26446281  88.09917355
  87.3553719   87.19008264  88.84297521  89.25619835  89.58677686
  87.52066116  87.27272727  89.00826446  86.69421488  88.09917355
  88.59504132  88.59504132  86.52892562  88.09917355  86.69421488
  85.95041322  86.61157025  86.52892562  87.85123967  88.34710744
  86.11570248  88.18181818  89.50413223  89.09090909  86.7768595
  87.10743802  87.10743802  87.9338843   87.60330579  86.19834711
  88.67768595  86.7768595   88.26446281  87.85123967  87.19008264
  87.85123967  88.26446281  87.3553719   88.18181818  87.85123967
  88.34710744  87.27272727  88.18181818  88.26446281  88.92561983
  89.17355372  88.59504132  87.9338843   88.42975207  88.59504132
  86.69421488  87.19008264  87.60330579  89.4214876   88.92561983]
87.89
0.91
[7 7 7 8 6 7 6 7 4 7 6 5 7 3 7 7 7 7 5 5 7 7 7 3 7 7 8 7 5 7 9 7 7 6 8 7 5
 8 7 6 8 8 7 7 7 7 8 4 5 5 8 7 6 8 3 7 5 7 8 7 7 8 7 7 7 9 8 6 6 7 7 7 6 7
 7 7 6 7 7 7 4 7 7 6 8 7 5 3 7 6 7 7 5 7 7 7 7 7 4 7]
BernoulliNB
[ 87.02479339  86.85950413  88.42975207  85.37190083  88.34710744
  87.10743802  87.60330579  86.03305785  86.28099174  86.36363636
  86.03305785  86.11570248  87.43801653  87.10743802  86.85950413
  87.27272727  88.76033058  87.27272727  87.85123967  87.60330579
  89.33884298  88.18181818  88.76033058  85.95041322  86.69421488
  87.3553719   86.28099174  86.19834711  87.43801653  87.3553719
  87.85123967  86.61157025  86.85950413  85.8677686   87.43801653
  87.3553719   87.43801653  87.43801653  87.52066116  87.02479339
  88.92561983  87.27272727  86.7768595   86.61157025  86.7768595
  86.85950413  88.34710744  86.7768595   87.27272727  88.92561983
  87.85123967  85.70247934  87.19008264  86.28099174  87.10743802
  86.52892562  86.94214876  85.95041322  88.51239669  86.28099174
  85.20661157  87.10743802  86.52892562  87.60330579  86.85950413
  86.69421488  88.42975207  89.25619835  86.61157025  85.12396694
  87.10743802  86.94214876  87.02479339  87.27272727  85.78512397
  87.85123967  85.45454545  87.3553719   87.60330579  85.2892562
  84.29752066  87.02479339  85.45454545  86.94214876  88.51239669
  88.01652893  86.11570248  84.54545455  88.09917355  87.9338843
  87.52066116  88.18181818  87.10743802  87.60330579  86.94214876
  86.69421488  85.70247934  86.61157025  87.9338843   88.59504132]
87.07
1.00
[ 9  8  7  9  8  7  8  8  9  7  9  9  7  9  8  8  8  8  5  8  7  8  8  8  8
  8  9  8  8  9  4  8  8  9  6  8  8  7  7  8  7  7  8  8  8  8  7  8  8  8
  7  9  8  9  8  9  8  8  7  8  8  7  7  8  8  7  6  7  9  9  7  8  9  8  8
  8  9  8  8 10  9  8 10  8  7  8  8  8  8  8  9  8  8  8  9  7  9  8  8  8]
AdaBoost
[ 88.34710744  88.51239669  89.91735537  87.76859504  88.59504132
  87.76859504  89.09090909  89.09090909  90.16528926  88.42975207
  88.51239669  88.34710744  88.51239669  88.09917355  88.51239669
  89.4214876   91.15702479  88.26446281  89.17355372  90.33057851
  91.40495868  90.33057851  91.32231405  86.94214876  88.76033058
  89.33884298  88.01652893  89.33884298  89.17355372  89.17355372
  87.68595041  87.76859504  89.09090909  87.27272727  87.9338843
  88.59504132  90.74380165  88.92561983  89.00826446  88.92561983
  89.91735537  87.52066116  88.67768595  89.25619835  88.92561983
  88.42975207  89.66942149  89.00826446  89.50413223  89.75206612
  89.58677686  88.59504132  89.50413223  88.18181818  87.52066116
  89.58677686  89.25619835  87.19008264  89.58677686  87.85123967
  87.19008264  88.26446281  87.68595041  89.83471074  89.50413223
  88.59504132  88.34710744  89.17355372  89.09090909  87.9338843
  89.17355372  88.92561983  88.92561983  88.92561983  88.34710744
  89.75206612  86.61157025  88.34710744  88.76033058  88.76033058
  87.43801653  88.67768595  89.91735537  88.84297521  90.90909091
  89.4214876   88.34710744  87.68595041  89.00826446  88.92561983
  89.91735537  88.92561983  89.00826446  90.24793388  90.24793388
  88.18181818  88.34710744  88.51239669  90.74380165  89.58677686]
88.90
0.95
[6 4 5 4 7 4 6 4 3 5 4 3 6 7 3 3 3 6 3 3 3 3 3 7 3 5 3 3 3 3 7 6 4 7 4 6 3
 4 5 3 3 6 6 4 5 3 3 3 3 4 3 6 3 4 5 3 3 3 3 4 3 5 3 3 4 5 7 8 6 6 4 3 3 3
 3 3 8 6 6 3 7 6 3 3 3 3 3 4 6 6 6 3 3 3 3 6 5 3 3 4]
RandomForest
[ 89.91735537  91.48760331  92.80991736  90.74380165  91.98347107
  91.73553719  91.65289256  92.31404959  90.90909091  91.98347107
  91.90082645  90.41322314  92.23140496  91.81818182  91.15702479
  92.39669421  91.73553719  90.66115702  92.31404959  91.98347107
  92.97520661  92.80991736  91.65289256  90.41322314  90.49586777
  91.81818182  91.73553719  91.23966942  93.47107438  92.14876033
  91.07438017  90.82644628  92.39669421  90.5785124   91.65289256
  92.47933884  92.39669421  92.72727273  91.23966942  91.40495868
  91.65289256  91.15702479  91.15702479  90.33057851  91.81818182
  91.23966942  91.40495868  91.90082645  91.73553719  91.73553719
  92.14876033  91.32231405  92.39669421  91.23966942  91.32231405
  92.0661157   91.15702479  88.59504132  91.32231405  90.41322314
  91.07438017  90.5785124   91.23966942  92.23140496  91.73553719
  90.08264463  90.24793388  92.0661157   92.14876033  90.82644628
  91.81818182  90.82644628  92.14876033  91.73553719  91.15702479
  92.23140496  91.90082645  91.90082645  91.90082645  91.65289256
  91.15702479  91.57024793  91.90082645  90.66115702  92.0661157
  91.32231405  91.65289256  90.16528926  90.99173554  91.65289256
  91.57024793  91.40495868  91.57024793  91.73553719  92.31404959
  91.65289256  90.5785124   92.80991736  92.23140496  92.72727273]
91.55
0.76
[1 1 1 2 1 2 2 1 2 1 1 2 1 2 2 2 1 2 2 2 1 1 2 1 2 2 1 1 1 1 1 1 1 2 1 2 1
 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 1 1 2 1 1
 1 1 2 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1 2 1 2 1 2 2]

MLP
Number of parameters combination: 16
LinearSVC
Number of parameters combination: 8
SVC
Number of parameters combination: 24
DecisionTree
Number of parameters combination: 72
k-NN
Number of parameters combination: 96
LogisticRegression
Number of parameters combination: 40
MultinomialNB
Number of parameters combination: 12
BernoulliNB
Number of parameters combination: 72
AdaBoost
Number of parameters combination: 50
RandomForest
Number of parameters combination: 72

<bound method MLPClassifier.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(200,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=100000, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)>
<bound method LinearSVC.get_params of LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',
     penalty='l2', random_state=None, tol=0.0001, verbose=0)>
<bound method SVC.get_params of SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovo', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)>
<bound method DecisionTreeClassifier.get_params of DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=4,
            min_weight_fraction_leaf=0.0, presort=True, random_state=None,
            splitter='best')>
<bound method KNeighborsClassifier.get_params of KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=7, p=2,
           weights='distance')>
<bound method LogisticRegression.get_params of LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100000, multi_class='ovr',
          n_jobs=1, penalty='l2', random_state=None, solver='liblinear',
          tol=0.0001, verbose=0, warm_start=False)>
<bound method MultinomialNB.get_params of MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)>
<bound method BernoulliNB.get_params of BernoulliNB(alpha=1e-10, binarize=0.0, class_prior=None, fit_prior=True)>
<bound method AdaBoostClassifier.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=0.5, n_estimators=250, random_state=None)>
<bound method RandomForestClassifier.get_params of RandomForestClassifier(bootstrap=False, class_weight=None,
            criterion='entropy', max_depth=None, max_features='log2',
            max_leaf_nodes=None, min_impurity_decrease=0.0,
            min_impurity_split=None, min_samples_leaf=1,
            min_samples_split=6, min_weight_fraction_leaf=0.0,
            n_estimators=250, n_jobs=1, oob_score=False, random_state=None,
            verbose=0, warm_start=False)>
